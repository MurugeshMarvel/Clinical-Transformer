{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import define_main_parser\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "#from dataset.prsa import PRSADataset\n",
    "from data.card import TransactionDataset\n",
    "from models.modules import TabFormerBertLM\n",
    "from scripts.utils import random_split_dataset\n",
    "#from data.datacollator import TransDataCollatorForLanguageModeling\n",
    "import data.datacollator as datacoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data.datacollator' from '/home/admin/murugesh/Clinical-Transformer/notebook/../data/datacollator.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(datacoll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "config = vars(Namespace(cached=False, checkpoint=0, data_extension='', data_fname='card_transaction.v3', data_root='./data/credit_card/', data_type='card', do_eval=False, do_train=True, field_ce=True, field_hs=64, flatten=False, jid=1, lm_type='bert', log_dir='sam/logs', mlm=True, mlm_prob=0.15, nrows=None, num_train_epochs=3, output_dir='sam', save_steps=500, seed=9, skip_user=False, stride=5, user_ids=None, vocab_file='vocab.nb'))\n",
    "config['data_root'] = \"../dataset/credit_card/\"\n",
    "config['output_dir'] = \"sample\"\n",
    "config['log_dir'] = \"sample/logs\"\n",
    "makedirs(config['output_dir'], exist_ok=True)\n",
    "makedirs(config['log_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config['seed']\n",
    "random.seed(seed)  # python\n",
    "np.random.seed(seed)  # numpy\n",
    "torch.manual_seed(seed)  # torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)  # torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 29.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TransactionDataset(root=config['data_root'],\n",
    "                            fname=config['data_fname'],\n",
    "                            fextension=\"\",\n",
    "                            vocab_dir=config['output_dir'],\n",
    "                            nrows=None,\n",
    "                            user_ids=None,\n",
    "                            seq_len=20,\n",
    "                            mlm=True,\n",
    "                            cached=config['cached'],\n",
    "                            stride=10,\n",
    "                            flatten=config['flatten'],\n",
    "                            return_labels=True,\n",
    "                            skip_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #return_data = torch.tensor(dataset.data[0], dtype=torch.long)\n",
    "# return_data = torch.tensor(dataset.data[0], dtype=torch.long).reshape(dataset.seq_len, -1)\n",
    "# return_data2 = (return_data, torch.tensor(dataset.labels[0], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lengths: train [17709]  valid [5903]  test [5903]\n",
      "# lengths: train [0.60]  valid [0.20]  test [0.20]\n"
     ]
    }
   ],
   "source": [
    "vocab = dataset.vocab\n",
    "custom_special_tokens = vocab.get_special_tokens()\n",
    "\n",
    "totalN = len(dataset)\n",
    "totalN = len(dataset)\n",
    "trainN = int(0.6 * totalN)\n",
    "\n",
    "valtestN = totalN - trainN\n",
    "valN = int(valtestN * 0.5)\n",
    "testN = valtestN - valN\n",
    "lengths = [trainN, valN, testN]\n",
    "print(f\"# lengths: train [{trainN}]  valid [{valN}]  test [{testN}]\")\n",
    "print(\"# lengths: train [{:.2f}]  valid [{:.2f}]  test [{:.2f}]\".format(trainN / totalN, valN / totalN,\n",
    "                                                                               testN / totalN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset, test_dataset = random_split_dataset(dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "collactor_cls = \"TransDataCollatorForLanguageModeling\"\n",
    "data_collator = datacoll.TransDataCollatorForLanguageModeling(\n",
    "        tokenizer=tab_net.tokenizer, mlm=True, mlm_probability=config['mlm_prob']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=200,\n",
    "            collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# for inps in tqdm(train_dataloader):\n",
    "#     print('out',inps['labels'])\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir=config['output_dir'],  # output directory\n",
    "        num_train_epochs=config['num_train_epochs'],  # total number of training epochs\n",
    "        logging_dir=config['log_dir'],  # directory for storing logs\n",
    "        save_steps=config['save_steps'],\n",
    "        do_train=config['do_train'],\n",
    "        # do_eval=args.do_eval,\n",
    "        # evaluation_strategy=\"epoch\",\n",
    "        prediction_loss_only=True,\n",
    "        overwrite_output_dir=True,\n",
    "        # eval_steps=10000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        model=tab_net.model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f0e99a316a0>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tab_net.model\n",
    "model = model.to('cuda:2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = {'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 5e-05}\n",
    "optim = torch.optim.AdamW(model.parameters(), **optim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 0/89 [00:00<?, ?it/s]/home/admin/murugesh/Clinical-Transformer/notebook/../data/datacollator.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labs = [torch.tensor(e[1], dtype=torch.long) for e in examples]\n",
      "/home/admin/murugesh/Clinical-Transformer/notebook/../data/datacollator.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples = [torch.tensor(e[0], dtype=torch.long) for e in examples]\n",
      "  0%|                                                                                                      | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'masked_lm_labels', 'Ouput'])\n",
      "inps tensor([[[    9,    14,    32,  ..., 10510, 10616,     1],\n",
      "         [    9,    14,    27,  ..., 10513, 10616,     1],\n",
      "         [    4,    14,    26,  ..., 10511, 10616,     1],\n",
      "         ...,\n",
      "         [    9,    14,    26,  ..., 10514, 10616,     1],\n",
      "         [    4,    14,    23,  ..., 10515, 10616,     1],\n",
      "         [    9,     4,    25,  ..., 10508, 10616,     1]],\n",
      "\n",
      "        [[    7,    21,     4,  ...,     4, 10616,     1],\n",
      "         [    7,    21,    32,  ..., 10510, 10616,     1],\n",
      "         [    7,     4,    30,  ..., 10522, 10616,     1],\n",
      "         ...,\n",
      "         [    7,    21,    23,  ..., 10518, 10616,     1],\n",
      "         [    7,    21,     4,  ..., 10507, 10616,     1],\n",
      "         [    7,    21,    23,  ..., 10507, 10616,     1]],\n",
      "\n",
      "        [[    9,    14,    29,  ..., 10539,     4,     1],\n",
      "         [    9,    14,    30,  ..., 10507, 10616,     1],\n",
      "         [    9,    14,    31,  ..., 10515, 10616,     1],\n",
      "         ...,\n",
      "         [    9,    14,    27,  ..., 10508,     4,     1],\n",
      "         [    9,     4,    28,  ..., 10508, 10616,     1],\n",
      "         [    9,    14,    28,  ..., 10511,     4,     1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    8,    17,    25,  ...,     4, 10616,     1],\n",
      "         [    8,    17,    30,  ..., 10530, 10616,     1],\n",
      "         [    8,    17,    30,  ..., 10529, 10616,     1],\n",
      "         ...,\n",
      "         [    4,    17,    24,  ..., 10530, 10616,     1],\n",
      "         [    8,    17,    28,  ...,     4, 10616,     1],\n",
      "         [    8,    17,    30,  ...,     4, 10616,     1]],\n",
      "\n",
      "        [[    4,    17,     4,  ..., 10515, 10616,     1],\n",
      "         [   11,    17,    27,  ..., 10514,     4,     1],\n",
      "         [    4,     4,     4,  ...,     4, 10616,     1],\n",
      "         ...,\n",
      "         [   11,    17,    30,  ...,     4, 10616,     1],\n",
      "         [   11,    17,    23,  ..., 10510, 10616,     1],\n",
      "         [   11,    17,    32,  ..., 10507, 10616,     1]],\n",
      "\n",
      "        [[    4,     4,    23,  ..., 10508, 10616,     1],\n",
      "         [   11,    15,    27,  ..., 10507, 10616,     1],\n",
      "         [   11,  4953,     4,  ..., 10517, 10616,     1],\n",
      "         ...,\n",
      "         [   11,    15,    26,  ...,   161, 10616,     1],\n",
      "         [   11,    15,    27,  ..., 10527, 10616,     1],\n",
      "         [   11,    15,     4,  ..., 10514, 10616,     1]]])\n",
      "masked_lm_labels tensor([[[ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [    9,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         ...,\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [    9,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,    14,  -100,  ...,  -100,  -100,  -100]],\n",
      "\n",
      "        [[ -100,  -100,    27,  ..., 10510,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,    21,  -100,  ...,  -100,  -100,  -100],\n",
      "         ...,\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,    32,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100]],\n",
      "\n",
      "        [[ -100,  -100,  -100,  ...,  -100, 10616,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,    31,  ...,  -100,  -100,  -100],\n",
      "         ...,\n",
      "         [ -100,  -100,  -100,  ...,  -100, 10616,  -100],\n",
      "         [ -100,    14,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100, 10616,  -100]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -100,  -100,  -100,  ..., 10517,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         ...,\n",
      "         [    8,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ..., 10521,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ..., 10529,  -100,  -100]],\n",
      "\n",
      "        [[   11,  -100,    23,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ..., 10514, 10616,  -100],\n",
      "         [   11,    17,    29,  ..., 10511,  -100,  -100],\n",
      "         ...,\n",
      "         [ -100,  -100,  -100,  ..., 10513, 10616,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100]],\n",
      "\n",
      "        [[   11,    15,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,    15,    25,  ...,  -100,  -100,  -100],\n",
      "         ...,\n",
      "         [ -100,  -100,  -100,  ..., 10513,  -100,  -100],\n",
      "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "         [ -100,  -100,    24,  ...,  -100,  -100,  -100]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for inps in tqdm(train_dataloader):\n",
    "    print(inps.keys())\n",
    "    print('inps', inps['input_ids'])\n",
    "    print('masked_lm_labels',inps['masked_lm_labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:14<00:00,  6.17it/s]\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "for inps in tqdm(train_dataloader):\n",
    "    #print(inps.keys())\n",
    "    #print(inps['input_ids'].shape)\n",
    "    #print(inps['masked_lm_labels'].shape)\n",
    "    #print(inps['masked_lm_labels'], )\n",
    "    optim.zero_grad()\n",
    "    labels = inps.pop(\"Ouput\")\n",
    "    model.train()\n",
    "    inps['input_ids'] = inps['input_ids'].to('cuda:2')\n",
    "    inps['masked_lm_labels'] = inps['masked_lm_labels'].to('cuda:2')\n",
    "    outputs =model(**inps)\n",
    "    #labels = inps.pop(\"labels\")\n",
    "    loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "    #loss.backward()\n",
    "    #optim.step()\n",
    "    total_loss += loss.item()\n",
    "    #print(loss)\n",
    "    # print(len(aa))\n",
    "    # print(\"Length of out - \", len(out))\n",
    "    # print('Ouput -', out[0].shape)\n",
    "    # #print('Ouput -', out[1].shape)\n",
    "    # print(aa[0])\n",
    "    # print(aa[1].shape)\n",
    "    # #aa.last_hidden_state\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(total_loss/len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in new_mode/config.json\n",
      "Model weights saved in new_mode/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model.save_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_val = torch.load('new_mode/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model = tab_net.model.tb_model.from_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(tab_net.model.tb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model.bert.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_classifier import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_fe_model = tab_net.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = LSTM(emb_inp_size=1062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_cls = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, custom_special_tokens,\n",
    "                 vocab,\n",
    "                 field_ce,\n",
    "                 flatten,\n",
    "                 ncols,\n",
    "                 field_hidden_size,\n",
    "                 bert_feature_size,\n",
    "                 base_model\n",
    "                 ):\n",
    "        super(Classifier, self).__init__()\n",
    "        '''\n",
    "        self.tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                        vocab=vocab,\n",
    "                                        field_ce=field_ce,\n",
    "                                        flatten=flatten,\n",
    "                                        ncols=ncols,\n",
    "                                        field_hidden_size=field_hidden_size)\n",
    "        '''\n",
    "        loaded_val = torch.load('new_mode/pytorch_model.bin')\n",
    "        base_model.load_state_dict(loaded_val)\n",
    "        #print(base_model)\n",
    "        for p in base_model.parameters():\n",
    "            p.requires_grad = True\n",
    "        self.field_transformer = base_model.tab_embeddings\n",
    "        self.bert = base_model.tb_model\n",
    "        \n",
    "\n",
    "\n",
    "        self.classifier = LSTM(emb_inp_size=bert_feature_size)\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids ,input_args):\n",
    "        field_embeddings = self.field_transformer(input_ids)\n",
    "        #input_args['input_ids'] = input_ids\n",
    "        bert_features = self.bert(inputs_embeds=field_embeddings, **input_args)\n",
    "        \n",
    "        bert_features = bert_features[1]\n",
    "        bert_features = bert_features.reshape((10, 20, 11, 1062))\n",
    "        bert_features = bert_features.reshape((200, 11, 1062))\n",
    "        cls_out = self.classifier(bert_features, T.as_tensor(([11])))\n",
    "        return cls_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = Classifier(custom_special_tokens,\n",
    "                 vocab=vocab,\n",
    "                    field_ce=config['field_ce'],\n",
    "                    flatten=config['flatten'],\n",
    "                    ncols=dataset.ncols,\n",
    "                    field_hidden_size=config['field_hs'],\n",
    "                 bert_feature_size=1062, base_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.tb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([232])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as T\n",
    "T.as_tensor(([232]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 20])\n",
      "torch.Size([20, 11])\n",
      "torch.Size([20, 11])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classif' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-309-15e75088729f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclass_out\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclassif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Class out - {class_out.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classif' is not defined"
     ]
    }
   ],
   "source": [
    "for inps in train_dataloade:\n",
    "    input_ids = inps.pop('input_ids')\n",
    "    #print(out.shape)\n",
    "    #print(input_ids.shape)\n",
    "    #print(inps['masked_lm_labels'].shape)\n",
    "    #print(inps['masked_lm_labels'], )\n",
    "    print(inps[0].shape)\n",
    "    print(inps[1].shape)\n",
    "    class_out =classif(input_ids, inps)\n",
    "    \n",
    "    print(f\"Class out - {class_out.shape}\")\n",
    "    print(class_out)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. append classifier with bert\n",
    "2. Freeze bert model after first train\n",
    "3. Use bert model and train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

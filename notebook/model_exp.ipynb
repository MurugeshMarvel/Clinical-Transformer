{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import define_main_parser\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "#from dataset.prsa import PRSADataset\n",
    "from data.card import TransactionDataset\n",
    "from models.modules import TabFormerBertLM\n",
    "from scripts.utils import random_split_dataset\n",
    "#from data.datacollator import TransDataCollatorForLanguageModeling\n",
    "import data.datacollator as datacoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data.datacollator' from '/home/admin/murugesh/Clinical-Transformer/notebook/../data/datacollator.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(datacoll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "config = vars(Namespace(cached=False, checkpoint=0, data_extension='', data_fname='card_transaction.v3', data_root='./data/credit_card/', data_type='card', do_eval=False, do_train=True, field_ce=True, field_hs=64, flatten=False, jid=1, lm_type='bert', log_dir='sam/logs', mlm=True, mlm_prob=0.15, nrows=None, num_train_epochs=3, output_dir='sam', save_steps=500, seed=9, skip_user=False, stride=5, user_ids=None, vocab_file='vocab.nb'))\n",
    "config['data_root'] = \"../dataset/credit_card/\"\n",
    "config['output_dir'] = \"sample\"\n",
    "config['log_dir'] = \"sample/logs\"\n",
    "makedirs(config['output_dir'], exist_ok=True)\n",
    "makedirs(config['log_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config['seed']\n",
    "random.seed(seed)  # python\n",
    "np.random.seed(seed)  # numpy\n",
    "torch.manual_seed(seed)  # torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)  # torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 31.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  6.46it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TransactionDataset(root=config['data_root'],\n",
    "                            fname=config['data_fname'],\n",
    "                            fextension=\"\",\n",
    "                            vocab_dir=config['output_dir'],\n",
    "                            nrows=None,\n",
    "                            user_ids=None,\n",
    "                            seq_len=20,\n",
    "                            mlm=True,\n",
    "                            cached=config['cached'],\n",
    "                            stride=10,\n",
    "                            flatten=config['flatten'],\n",
    "                            return_labels=True,\n",
    "                            skip_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30432/3874821253.py:3: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return_data2 = (return_data, torch.tensor(dataset.labels[20], dtype=torch.long))\n"
     ]
    }
   ],
   "source": [
    "return_data = torch.tensor(dataset.data[20], dtype=torch.long)\n",
    "return_data = torch.tensor(dataset.data[20], dtype=torch.long).reshape(dataset.seq_len, -1)\n",
    "return_data2 = (return_data, torch.tensor(dataset.labels[20], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [return_data2 for _ in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30432/2528551595.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labs = [torch.tensor(e[1], dtype=torch.long) for e in b]\n"
     ]
    }
   ],
   "source": [
    "labs = [torch.tensor(e[1], dtype=torch.long) for e in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lengths: train [17709]  valid [5903]  test [5903]\n",
      "# lengths: train [0.60]  valid [0.20]  test [0.20]\n"
     ]
    }
   ],
   "source": [
    "vocab = dataset.vocab\n",
    "custom_special_tokens = vocab.get_special_tokens()\n",
    "\n",
    "totalN = len(dataset)\n",
    "totalN = len(dataset)\n",
    "trainN = int(0.6 * totalN)\n",
    "\n",
    "valtestN = totalN - trainN\n",
    "valN = int(valtestN * 0.5)\n",
    "testN = valtestN - valN\n",
    "lengths = [trainN, valN, testN]\n",
    "print(f\"# lengths: train [{trainN}]  valid [{valN}]  test [{testN}]\")\n",
    "print(\"# lengths: train [{:.2f}]  valid [{:.2f}]  test [{:.2f}]\".format(trainN / totalN, valN / totalN,\n",
    "                                                                               testN / totalN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset, test_dataset = random_split_dataset(dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "collactor_cls = \"TransDataCollatorForLanguageModeling\"\n",
    "data_collator = datacoll.TransDataCollatorForLanguageModeling(\n",
    "        tokenizer=tab_net.tokenizer, mlm=True, mlm_probability=config['mlm_prob']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=100,\n",
    "            collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#         output_dir=config['output_dir'],  # output directory\n",
    "#         num_train_epochs=config['num_train_epochs'],  # total number of training epochs\n",
    "#         logging_dir=config['log_dir'],  # directory for storing logs\n",
    "#         save_steps=config['save_steps'],\n",
    "#         do_train=config['do_train'],\n",
    "#         # do_eval=args.do_eval,\n",
    "#         # evaluation_strategy=\"epoch\",\n",
    "#         prediction_loss_only=True,\n",
    "#         overwrite_output_dir=True,\n",
    "#         # eval_steps=10000\n",
    "#     )\n",
    "# trainer = Trainer(\n",
    "#         model=tab_net.model,\n",
    "#         args=training_args,\n",
    "#         data_collator=data_collator,\n",
    "#         train_dataset=train_dataset,\n",
    "#         eval_dataset=eval_dataset,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tab_net.model\n",
    "model = model.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = {'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 5e-05}\n",
    "optim = torch.optim.AdamW(model.parameters(), **optim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'masked_lm_labels', 'Ouput'])\n"
     ]
    }
   ],
   "source": [
    "for inps in train_dataloader:\n",
    "    print(inps.keys())\n",
    "    inps['masked_lm_labels'] = torch.clone(inps['input_ids'])\n",
    "    #print(inps['input_ids'] == inps['masked_lm_labels'])\n",
    "    #print(inps['Ouput'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                     | 0/178 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:3', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                     | 0/178 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "for inps in tqdm(train_dataloader):\n",
    "    #print(inps.keys())\n",
    "    #print(inps['input_ids'].shape)\n",
    "    #print(inps['masked_lm_labels'].shape)\n",
    "    #print(inps['masked_lm_labels'], )\n",
    "    optim.zero_grad()\n",
    "    #print(inps['input_ids'].shape)\n",
    "    labels = inps.pop(\"Ouput\")\n",
    "    model.train()\n",
    "    inps['input_ids'] = inps['input_ids'].to('cuda:3')\n",
    "    inps['masked_lm_labels'] = inps['masked_lm_labels'].to('cuda:3')\n",
    "    outputs =model(**inps)\n",
    "    \n",
    "    loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    total_loss += loss.item()\n",
    "    break\n",
    "    #print(loss)\n",
    "    # print(len(aa))\n",
    "    # print(\"Length of out - \", len(out))\n",
    "    # print('Ouput -', out[0].shape)\n",
    "    # #print('Ouput -', out[1].shape)\n",
    "    # print(aa[0])\n",
    "    # print(aa[1].shape)\n",
    "    # #aa.last_hidden_state\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(total_loss/len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('new_mode1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "#                                   vocab=vocab,\n",
    "#                                   field_ce=config['field_ce'],\n",
    "#                                   flatten=config['flatten'],\n",
    "#                                   ncols=dataset.ncols,\n",
    "#                                   field_hidden_size=config['field_hs']\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model.save_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_val = torch.load('new_mode1/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model = tab_net.model.tb_model.from_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(tab_net.model.tb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model.bert.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-23c5aa56e56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_classifier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlstm_classfr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_classfr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import models.lstm_classifier as lstm_classfr\n",
    "reload(lstm_classfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_fe_model = tab_net.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = lstm_classfr.LSTM(emb_inp_size=1062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_cls = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, custom_special_tokens,\n",
    "                 vocab,\n",
    "                 field_ce,\n",
    "                 flatten,\n",
    "                 ncols,\n",
    "                 field_hidden_size,\n",
    "                 bert_feature_size,\n",
    "                 base_model\n",
    "                 ):\n",
    "        super(Classifier, self).__init__()\n",
    "        '''\n",
    "        self.tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                        vocab=vocab,\n",
    "                                        field_ce=field_ce,\n",
    "                                        flatten=flatten,\n",
    "                                        ncols=ncols,\n",
    "                                        field_hidden_size=field_hidden_size)\n",
    "        '''\n",
    "        loaded_val = torch.load('new_mode1/pytorch_model.bin')\n",
    "        base_model.load_state_dict(loaded_val)\n",
    "        #print(base_model)\n",
    "        for p in base_model.parameters():\n",
    "            p.requires_grad = True\n",
    "        self.field_transformer = base_model.tab_embeddings\n",
    "        self.bert = base_model.tb_model\n",
    "        \n",
    "\n",
    "\n",
    "        self.classifier = lstm_classfr.LSTM(emb_inp_size=bert_feature_size)\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids ,input_args):\n",
    "        field_embeddings = self.field_transformer(input_ids)\n",
    "        #input_args['input_ids'] = input_ids\n",
    "        bert_features = self.bert(inputs_embeds=field_embeddings, **input_args)\n",
    "        \n",
    "        bert_features = bert_features[1]\n",
    "        print(bert_features.shape)\n",
    "        bert_features = bert_features.reshape((50, 20, 11, 8721))\n",
    "        bert_features = bert_features.reshape((50, 220, 8721))\n",
    "        cls_out = self.classifier(bert_features, T.as_tensor(([11])))\n",
    "        \n",
    "        return cls_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = Classifier(custom_special_tokens,\n",
    "                 vocab=vocab,\n",
    "                    field_ce=config['field_ce'],\n",
    "                    flatten=config['flatten'],\n",
    "                    ncols=dataset.ncols,\n",
    "                    field_hidden_size=config['field_hs'],\n",
    "                 bert_feature_size=8721, base_model=model)\n",
    "classif = classif.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.tb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([232])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as T\n",
    "T.as_tensor(([232]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_fn = torch.optim.Adadelta(params=classif.parameters(), lr=0.1, rho=0.95, eps=1e-08)\n",
    "loss_fn = T.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'masked_lm_labels', 'Ouput'])\n",
      "torch.Size([50, 220, 8721])\n",
      "inp_shaep torch.Size([50, 220, 8721])\n",
      "Before fc torch.Size([1, 256])\n",
      "After fc torch.Size([1, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-92acd7c26510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked_lm_labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked_lm_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclassif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-b9c2b773b164>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_args)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mbert_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8721\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mbert_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8721\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcls_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/murugesh/Clinical-Transformer/models/lstm_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp_emb, inp_len)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#text_fea = torch.squeeze(text_fea, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After fc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_fea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtext_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_fea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "for inps in train_dataloader:\n",
    "    print(inps.keys())\n",
    "    input_ids = inps.pop('input_ids')\n",
    "    out = inps.pop('Ouput')\n",
    "    classif.train()\n",
    "    \n",
    "    #print(out)\n",
    "    #print(input_ids.shape)\n",
    "    #print(inps['masked_lm_labels'].shape)\n",
    "    #print(inps['masked_lm_labels'], )\n",
    "    #print(inps[0].shape)\n",
    "    #print(inps[1].shape)\n",
    "    input_ids = input_ids.to('cuda:3')\n",
    "    inps['masked_lm_labels'] = inps['masked_lm_labels'].to('cuda:3')\n",
    "    preds =classif(input_ids, inps)\n",
    "    print(preds)\n",
    "    preds = preds.view(preds.size(0))\n",
    "    loss = loss_fn(preds.float(), out.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Class out - {class_out.shape}\")\n",
    "    print(class_out)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. append classifier with bert\n",
    "2. Freeze bert model after first train\n",
    "3. Use bert model and train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = T.nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(hn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(hn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import define_main_parser\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "#from dataset.prsa import PRSADataset\n",
    "from data.card import TransactionDataset\n",
    "#from models.modules import TabFormerBertLM\n",
    "from models import modules\n",
    "from models import tabformer_bert\n",
    "from scripts.utils import random_split_dataset\n",
    "#from data.datacollator import TransDataCollatorForLanguageModeling\n",
    "import data.datacollator as datacoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.tabformer_bert' from '/home/admin/murugesh/Clinical-Transformer/notebook/../models/tabformer_bert.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(datacoll)\n",
    "reload(modules)\n",
    "reload(tabformer_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "config = vars(Namespace(cached=False, checkpoint=0, data_extension='', data_fname='card_transaction.v3', data_root='./data/credit_card/', data_type='card', do_eval=False, do_train=True, field_ce=True, field_hs=64, flatten=False, jid=1, lm_type='bert', log_dir='sam/logs', mlm=True, mlm_prob=0.15, nrows=None, num_train_epochs=3, output_dir='sam', save_steps=500, seed=9, skip_user=False, stride=5, user_ids=None, vocab_file='vocab.nb'))\n",
    "config['data_root'] = \"../dataset/credit_card/\"\n",
    "config['output_dir'] = \"sample\"\n",
    "config['log_dir'] = \"sample/logs\"\n",
    "makedirs(config['output_dir'], exist_ok=True)\n",
    "makedirs(config['log_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config['seed']\n",
    "random.seed(seed)  # python\n",
    "np.random.seed(seed)  # numpy\n",
    "torch.manual_seed(seed)  # torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)  # torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 31.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.88it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TransactionDataset(root=config['data_root'],\n",
    "                            fname=config['data_fname'],\n",
    "                            fextension=\"\",\n",
    "                            vocab_dir=config['output_dir'],\n",
    "                            nrows=None,\n",
    "                            user_ids=None,\n",
    "                            seq_len=20,\n",
    "                            mlm=True,\n",
    "                            cached=config['cached'],\n",
    "                            stride=10,\n",
    "                            flatten=config['flatten'],\n",
    "                            return_labels=True,\n",
    "                            skip_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9259/3874821253.py:3: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return_data2 = (return_data, torch.tensor(dataset.labels[20], dtype=torch.long))\n"
     ]
    }
   ],
   "source": [
    "return_data = torch.tensor(dataset.data[20], dtype=torch.long)\n",
    "return_data = torch.tensor(dataset.data[20], dtype=torch.long).reshape(dataset.seq_len, -1)\n",
    "return_data2 = (return_data, torch.tensor(dataset.labels[20], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [return_data2 for _ in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7801/2528551595.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labs = [torch.tensor(e[1], dtype=torch.long) for e in b]\n"
     ]
    }
   ],
   "source": [
    "labs = [torch.tensor(e[1], dtype=torch.long) for e in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lengths: train [17709]  valid [5903]  test [5903]\n",
      "# lengths: train [0.60]  valid [0.20]  test [0.20]\n"
     ]
    }
   ],
   "source": [
    "vocab = dataset.vocab\n",
    "custom_special_tokens = vocab.get_special_tokens()\n",
    "\n",
    "totalN = len(dataset)\n",
    "totalN = len(dataset)\n",
    "trainN = int(0.6 * totalN)\n",
    "\n",
    "valtestN = totalN - trainN\n",
    "valN = int(valtestN * 0.5)\n",
    "testN = valtestN - valN\n",
    "lengths = [trainN, valN, testN]\n",
    "print(f\"# lengths: train [{trainN}]  valid [{valN}]  test [{testN}]\")\n",
    "print(\"# lengths: train [{:.2f}]  valid [{:.2f}]  test [{:.2f}]\".format(trainN / totalN, valN / totalN,\n",
    "                                                                               testN / totalN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset, test_dataset = random_split_dataset(dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['flatten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = modules.TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "collactor_cls = \"TransDataCollatorForLanguageModeling\"\n",
    "data_collator = datacoll.TransDataCollatorForLanguageModeling(\n",
    "        tokenizer=tab_net.tokenizer, mlm=True, mlm_probability=config['mlm_prob']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=2,\n",
    "            collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#         output_dir=config['output_dir'],  # output directory\n",
    "#         num_train_epochs=config['num_train_epochs'],  # total number of training epochs\n",
    "#         logging_dir=config['log_dir'],  # directory for storing logs\n",
    "#         save_steps=config['save_steps'],\n",
    "#         do_train=config['do_train'],\n",
    "#         # do_eval=args.do_eval,\n",
    "#         # evaluation_strategy=\"epoch\",\n",
    "#         prediction_loss_only=True,\n",
    "#         overwrite_output_dir=True,\n",
    "#         # eval_steps=10000\n",
    "#     )\n",
    "# trainer = Trainer(\n",
    "#         model=tab_net.model,\n",
    "#         args=training_args,\n",
    "#         data_collator=data_collator,\n",
    "#         train_dataset=train_dataset,\n",
    "#         eval_dataset=eval_dataset,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tab_net.model\n",
    "model = model.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = {'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 5e-05}\n",
    "optim = torch.optim.AdamW(model.parameters(), **optim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'masked_lm_labels', 'Ouput'])\n"
     ]
    }
   ],
   "source": [
    "for inps in train_dataloader:\n",
    "    print(inps.keys())\n",
    "    inps['masked_lm_labels'] = torch.clone(inps['input_ids'])\n",
    "    #print(inps['input_ids'] == inps['masked_lm_labels'])\n",
    "    #print(inps['Ouput'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                    | 0/8855 [00:00<?, ?it/s]/home/admin/murugesh/Clinical-Transformer/notebook/../data/datacollator.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labs = [torch.tensor(e[1], dtype=torch.long) for e in examples]\n",
      "/home/admin/murugesh/Clinical-Transformer/notebook/../data/datacollator.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples = [torch.tensor(e[0], dtype=torch.long) for e in examples]\n",
      "  0%|                                                                                                    | 0/8855 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Input Args - dict_keys(['masked_lm_labels'])\n",
      "Last Hidden State shape torch.Size([2, 20, 704])\n",
      "Sequence Output shape - torch.Size([2, 20, 704])\n",
      "Output shape - [2, 20, 704]\n",
      "Expected shape - [2, 220, -1]\n",
      "Sequence output - torch.Size([2, 220, 64])\n",
      "Masked lm labels - torch.Size([2, 220])\n",
      "field_name Card\n",
      "nfeas 6\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[-0.7298,  0.1460, -0.0591,  0.4848,  0.0129, -0.0640],\n",
      "        [-0.0802,  0.0366, -0.3693,  0.5374, -0.1442,  0.8202],\n",
      "        [-0.8304, -0.2112, -0.8067,  0.5468,  0.2112,  0.8113],\n",
      "        [-0.0559,  0.7708, -0.1172,  0.1264, -0.1639,  0.5160],\n",
      "        [-0.5581, -0.1573, -0.7658,  0.1829, -0.4744,  0.6320],\n",
      "        [-0.8758,  0.6800, -0.3678, -0.1106,  0.4389,  0.7890],\n",
      "        [-0.5957,  0.3707, -0.4952,  0.9009,  0.3412, -0.0571],\n",
      "        [-0.3233,  0.5991, -0.7706,  0.8430,  0.3551,  0.7675],\n",
      "        [-0.4736,  0.0540, -0.4739,  0.3214, -0.0373,  0.1755],\n",
      "        [-0.6975,  0.2345, -0.5206,  0.6233, -0.1110,  0.1473],\n",
      "        [-0.1576,  0.1246, -0.8922,  0.4667, -0.0871,  0.2562],\n",
      "        [-0.1974,  0.3977, -0.2371, -0.1230, -0.0534,  0.7617],\n",
      "        [-0.3093,  0.2192, -0.5826,  1.0101,  0.2050,  0.2212],\n",
      "        [-0.4156, -0.2013, -0.5764,  0.6412, -0.2522,  0.3980],\n",
      "        [-0.2629,  0.6353, -0.2511,  0.6432,  0.2580,  0.4831],\n",
      "        [-0.7936,  0.5177, -0.3724,  0.6776,  0.3818,  0.1824],\n",
      "        [-0.2725,  0.5696, -0.6841,  0.6875, -0.0483,  0.0133],\n",
      "        [-0.1015,  0.6010, -0.1172,  0.4018, -0.2764,  0.4008],\n",
      "        [-0.2533,  0.0314, -0.3248,  0.6105, -0.4438,  0.7615],\n",
      "        [-0.2473,  0.3508, -0.3403,  0.2184, -0.1242,  0.1771],\n",
      "        [ 0.1752,  0.7618,  0.3644,  0.4583,  0.8575, -0.0976],\n",
      "        [ 0.3794,  0.2035,  0.4355,  0.4935,  0.3602, -0.8303],\n",
      "        [ 0.1603,  0.6520,  0.1725,  0.3071,  0.2584, -1.1992],\n",
      "        [ 0.4675,  0.1984,  0.0166, -0.1626,  0.0725, -0.1871],\n",
      "        [-0.0446,  0.5367, -0.1046,  0.0970,  0.4247,  0.0208],\n",
      "        [ 0.7215,  0.6116,  0.2673,  0.2906, -0.0310, -0.6309],\n",
      "        [-0.1315,  0.8200, -0.0020,  0.8006,  0.4179, -1.1134],\n",
      "        [ 0.4830, -0.4687, -0.0180,  0.5961,  0.1218, -0.8698],\n",
      "        [-0.1950,  0.6960, -0.2814,  0.6640,  0.4131, -0.7883],\n",
      "        [-0.1319,  0.9659,  0.0749, -0.1406,  0.2554, -0.4980],\n",
      "        [ 0.3397,  0.8034, -0.2769,  0.2108,  0.9426, -0.6936],\n",
      "        [ 0.5223,  0.5709,  0.3665,  0.0677, -0.0864, -0.4385],\n",
      "        [ 0.1376,  0.6236, -0.4051,  0.6635,  0.6937, -1.2904],\n",
      "        [-0.0592,  0.8982,  0.4018,  0.7131,  0.8881, -0.7136],\n",
      "        [ 0.4740,  0.6904,  0.2359,  0.0177, -0.3448, -0.4135],\n",
      "        [ 0.0827,  0.3077, -0.3795,  0.0713,  1.2841,  0.0222],\n",
      "        [ 0.1001,  0.5672,  0.0696,  0.1018,  0.5015, -0.3088],\n",
      "        [ 0.3611,  0.0616, -0.4905,  0.3898,  0.3688, -0.6021],\n",
      "        [ 0.1029, -0.2436,  0.0532,  0.2020,  0.5597,  0.1293],\n",
      "        [ 0.5056,  0.8587,  0.9245,  0.1918, -0.2405, -0.4200]],\n",
      "       device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    0, -100,\n",
      "        -100, -100, -100, -100], device='cuda:3')\n",
      "field_name Timestamp\n",
      "nfeas 10\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[ 1.5213e-01,  2.8479e-01, -7.9511e-01,  2.2618e-01, -1.8644e-01,\n",
      "          7.1475e-01, -2.2800e-01, -7.7434e-01,  4.7611e-01,  6.6330e-01],\n",
      "        [ 4.6521e-02,  9.3664e-01, -5.3310e-01,  9.2057e-01, -1.2217e-01,\n",
      "          1.1681e+00, -3.3434e-01,  1.6218e-01,  6.7120e-01,  9.3979e-01],\n",
      "        [ 2.0850e-01,  3.6889e-01, -5.0288e-01,  6.9969e-01,  1.2615e-01,\n",
      "          2.9150e-01, -1.1457e+00, -4.1477e-01,  4.7955e-01,  7.3656e-01],\n",
      "        [ 5.4527e-01,  1.0062e+00, -6.8387e-02, -1.9464e-02,  1.0644e-01,\n",
      "          6.3506e-01, -3.3287e-01, -1.8568e-03,  2.4532e-01,  1.1275e+00],\n",
      "        [ 7.8793e-02, -8.8563e-01, -5.0251e-01,  6.6598e-02, -4.9427e-02,\n",
      "         -1.6743e-01, -1.5367e-01, -7.7226e-01, -8.0326e-01,  2.0415e-01],\n",
      "        [ 6.1218e-01,  5.5696e-01, -9.3002e-01,  4.6029e-02,  9.1020e-01,\n",
      "          6.0951e-01, -5.3845e-01, -2.0937e-01,  7.8105e-02,  4.1863e-01],\n",
      "        [ 2.0152e-01, -2.6584e-02, -5.1789e-01,  2.2682e-01, -2.3251e-02,\n",
      "          6.4056e-01, -4.1120e-01, -3.7941e-01,  2.0005e-01,  6.4267e-01],\n",
      "        [ 9.2639e-01,  4.1617e-01, -7.6793e-01,  7.3133e-01, -2.3188e-01,\n",
      "          8.8310e-01, -5.9757e-01, -5.9306e-01,  1.0256e+00,  1.1396e+00],\n",
      "        [ 1.0368e+00,  2.5557e-01, -1.6300e-01,  9.0036e-01,  3.2713e-02,\n",
      "          7.9635e-01,  5.4151e-01, -2.9215e-01,  7.4972e-02,  1.1255e+00],\n",
      "        [ 9.0567e-01, -3.7964e-01, -5.4740e-01,  3.7273e-01,  1.4849e-01,\n",
      "          1.4887e+00,  1.0730e-01, -3.7826e-01,  1.9311e-01,  3.9050e-01],\n",
      "        [ 6.6830e-01,  6.6423e-01, -9.4772e-01,  1.1163e+00,  1.8121e-01,\n",
      "          7.7925e-01, -1.3724e+00, -6.2165e-01,  8.6557e-01,  6.1990e-01],\n",
      "        [-7.4150e-03,  5.8527e-01, -8.7973e-01,  7.1920e-01,  3.6108e-01,\n",
      "          4.5035e-01, -7.2854e-01, -1.4616e-01,  9.0143e-01,  4.7715e-01],\n",
      "        [ 8.7835e-01,  5.3964e-01, -9.7560e-01,  9.9202e-01,  3.2263e-02,\n",
      "          2.5532e-01, -5.9911e-01, -5.6679e-01,  3.9212e-02,  7.0364e-01],\n",
      "        [ 4.5501e-01,  3.3109e-01, -1.0008e-01,  8.7077e-01,  3.8021e-02,\n",
      "          3.0325e-01, -4.7147e-01, -5.5505e-01,  5.0712e-01,  5.0281e-01],\n",
      "        [ 3.6096e-01,  8.4391e-02, -1.4043e-01,  4.1193e-01,  4.2562e-01,\n",
      "          8.9362e-01,  4.4604e-01, -1.2181e-03, -1.9442e-02,  1.1391e-01],\n",
      "        [ 5.1201e-01,  6.3521e-01, -3.2801e-01,  7.9457e-01, -2.0240e-01,\n",
      "          7.2385e-01, -6.9139e-01, -6.4325e-01,  7.3314e-02,  3.9236e-01],\n",
      "        [-6.5395e-02,  5.5870e-01, -4.2633e-01,  6.7720e-01,  4.7416e-01,\n",
      "          3.8137e-01, -4.7944e-01, -4.5012e-01,  6.0567e-01,  2.7750e-01],\n",
      "        [ 2.3306e-01, -1.9443e-01, -1.2237e+00, -2.2950e-01,  4.5644e-01,\n",
      "          7.9915e-01, -1.3872e+00, -8.2058e-01,  6.2078e-01, -1.4835e-01],\n",
      "        [ 1.6710e-01,  5.5360e-01, -5.3565e-01,  3.0750e-01, -1.2924e-01,\n",
      "          4.8091e-01, -5.0567e-01, -6.9919e-02,  8.9841e-01,  6.6881e-01],\n",
      "        [ 3.6844e-01,  6.3204e-01, -4.7631e-01,  1.8131e-01,  2.6500e-01,\n",
      "          4.7768e-01,  8.0490e-03, -9.0991e-01,  8.9094e-01,  4.1792e-01],\n",
      "        [-8.3918e-01,  6.6456e-01,  5.0819e-01, -1.6405e-01,  1.8256e-01,\n",
      "          4.4717e-01, -2.0354e-01,  6.6114e-01,  2.6315e-01,  6.3507e-01],\n",
      "        [ 4.3793e-02,  4.5000e-01,  1.5602e-01, -2.4294e-01, -6.2495e-02,\n",
      "          5.1336e-01, -2.8094e-01,  2.8876e-01,  1.2753e-01,  3.6749e-01],\n",
      "        [ 3.2969e-01,  1.4717e+00,  3.0901e-01, -5.7197e-01,  8.1751e-01,\n",
      "          2.3968e-01,  4.4248e-01,  2.3057e-01, -8.2224e-01,  2.3852e-01],\n",
      "        [-9.2933e-02,  4.3232e-01,  5.6440e-01, -3.0729e-01,  2.4565e-01,\n",
      "          4.0174e-01, -1.3462e-02,  7.1364e-01, -3.6145e-01,  9.0957e-01],\n",
      "        [-1.5451e-01,  5.2948e-02,  2.1899e-01, -6.3215e-01,  3.5196e-01,\n",
      "          6.4760e-01, -2.2410e-01, -6.6689e-01, -1.3766e-01,  2.3800e-01],\n",
      "        [-3.2553e-01,  6.9477e-01,  5.5594e-01, -1.9349e-01,  8.9348e-02,\n",
      "          8.7237e-01,  1.4246e-01,  1.3491e-01,  2.0720e-01,  5.5743e-01],\n",
      "        [ 1.7123e-02,  3.9118e-02,  8.6370e-01, -2.4027e-01,  1.3519e-02,\n",
      "          9.9498e-02, -9.4353e-02,  2.1726e-01, -1.1552e-01, -1.5762e-01],\n",
      "        [ 2.1082e-01,  3.1288e-01,  2.5912e-01, -8.7944e-01, -3.2024e-01,\n",
      "          2.0221e-01,  1.5086e-02,  2.1319e-01,  7.6989e-02,  4.3264e-01],\n",
      "        [ 1.9415e-01,  1.8105e-01,  5.5632e-02, -1.2443e-01, -1.1540e-01,\n",
      "          3.7497e-01,  3.2922e-01,  3.6110e-01, -5.3629e-01,  4.0072e-01],\n",
      "        [-1.9307e-01, -9.0539e-02,  3.3438e-01, -3.9412e-01,  4.6396e-02,\n",
      "          4.7610e-01,  1.6672e-01, -4.1210e-01, -7.4716e-01, -6.9238e-02],\n",
      "        [-1.6809e-01,  6.5173e-01,  1.7084e-01,  5.0510e-02,  1.3454e-01,\n",
      "          1.0579e+00,  2.3057e-01,  5.9321e-01, -1.4677e-01,  4.8480e-01],\n",
      "        [-4.1597e-02,  6.3823e-01,  1.7768e-01, -2.5572e-01, -3.6974e-02,\n",
      "          7.0630e-01,  5.5317e-01, -2.2970e-01,  3.1135e-01,  4.1238e-01],\n",
      "        [-1.3792e-01,  4.1256e-01,  2.1996e-01, -6.1977e-01, -6.6580e-01,\n",
      "          8.9604e-01,  9.1207e-02,  3.7693e-01,  4.4463e-01,  1.2416e-01],\n",
      "        [-4.8709e-01,  7.3728e-01,  4.5103e-01, -2.0690e-01,  1.6162e-01,\n",
      "          4.0288e-01, -7.2117e-02, -2.9423e-01,  2.0140e-01,  5.7367e-01],\n",
      "        [-6.0278e-01,  6.0983e-01,  3.6467e-01, -4.3501e-01,  3.9777e-01,\n",
      "          4.7466e-01,  5.1540e-01,  3.1525e-01, -2.1579e-01,  4.0289e-01],\n",
      "        [ 1.4282e-01,  3.7957e-01,  1.9875e-02, -7.7130e-01,  9.2844e-02,\n",
      "          1.0176e+00, -1.5294e-02,  5.4192e-01, -6.4299e-01,  4.9283e-01],\n",
      "        [ 6.6475e-02,  4.7603e-01,  3.3823e-01, -5.3554e-02,  6.1445e-02,\n",
      "         -1.2728e-02, -3.6432e-01,  2.8974e-01,  6.5044e-02,  3.6253e-01],\n",
      "        [ 1.2639e-01,  4.4821e-01,  6.9690e-01,  1.9887e-02,  1.3885e-01,\n",
      "          1.6931e-01, -9.5893e-02,  8.0300e-01, -8.5248e-01, -2.3273e-02],\n",
      "        [-2.5063e-01,  8.7609e-02, -3.4714e-01, -6.3829e-01, -3.3386e-01,\n",
      "          4.2967e-01,  4.7192e-01,  7.4261e-01, -6.8014e-01,  1.3009e-01],\n",
      "        [-2.4836e-01,  6.5339e-02, -7.1380e-01, -8.0998e-01,  2.1545e-01,\n",
      "          7.4023e-01,  3.3369e-01,  1.0740e-01, -3.5879e-01, -1.3639e-01]],\n",
      "       device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100,    1, -100, -100, -100, -100,    8, -100,\n",
      "        -100, -100, -100, -100, -100,    8, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100,    8], device='cuda:3')\n",
      "field_name Amount\n",
      "nfeas 10\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[ 0.4299,  0.7484, -0.6535, -0.2737,  0.3181, -0.1571, -0.4822,  0.1676,\n",
      "         -0.0318,  0.5109],\n",
      "        [ 0.3556,  0.0912,  0.1818, -0.0612,  1.0448,  0.3317, -0.0014,  0.8845,\n",
      "          0.1410,  0.3235],\n",
      "        [ 0.2216,  0.3081, -0.2599,  0.1598,  0.9826,  0.0276, -0.4657,  0.3425,\n",
      "          0.2394, -0.0803],\n",
      "        [ 0.4479,  0.2613, -0.3105,  0.4991,  0.8516, -0.2919, -0.6113, -0.0725,\n",
      "          0.7258,  0.5923],\n",
      "        [ 0.5522,  0.8337, -0.3391,  0.2703, -0.2005,  0.2597, -0.4275, -0.0816,\n",
      "          0.7493,  0.3935],\n",
      "        [ 0.1193,  0.6677, -0.1375, -0.2699,  0.2063, -0.5275, -0.6653,  0.4602,\n",
      "         -0.3810, -0.1488],\n",
      "        [-0.0936,  0.8366, -0.0410,  0.1564, -0.1181,  0.2124, -0.4957,  0.0460,\n",
      "         -0.1823,  0.0367],\n",
      "        [ 0.8517,  0.3360, -0.5668,  0.1667,  0.4578, -0.2146, -0.4785,  0.9923,\n",
      "         -0.0575,  0.3458],\n",
      "        [ 0.6457,  0.7003,  0.0380, -0.4756,  0.6218,  0.3724, -0.3917,  0.8970,\n",
      "         -0.1942,  0.6010],\n",
      "        [ 0.5021,  0.5496, -0.4624,  0.2331, -0.0503,  0.6620, -0.5332, -0.3248,\n",
      "          0.8250,  0.6949],\n",
      "        [ 0.2806,  0.0250, -0.3430,  0.7020,  0.6796,  0.5721, -0.4151, -0.1040,\n",
      "          0.1265, -0.0679],\n",
      "        [ 1.0972,  0.5283, -0.4422,  0.2256,  0.1609,  0.5822, -0.6090,  0.4676,\n",
      "          1.1286,  0.3011],\n",
      "        [ 0.6938,  0.1952, -0.6014,  0.2835,  0.9854, -0.2126, -0.5653,  0.8979,\n",
      "          0.2603,  0.7469],\n",
      "        [ 0.5053,  0.3812, -0.0577,  0.6878,  0.1842,  0.7508, -0.6213, -0.2033,\n",
      "          0.3419,  0.3516],\n",
      "        [-0.0071,  0.3460,  0.2615, -0.3607,  1.1202, -0.0569, -0.2164,  0.6687,\n",
      "          0.2921,  0.3722],\n",
      "        [ 0.3845,  0.6198, -0.8251,  0.2997,  0.3578, -0.2145, -0.5547,  0.7133,\n",
      "          0.7462,  0.3597],\n",
      "        [ 0.2915,  0.8496, -0.7726,  0.6244,  1.2932, -0.0135, -0.7077, -0.0369,\n",
      "          0.1079, -0.0960],\n",
      "        [ 0.1753,  0.4466,  0.1640,  0.4912,  1.1237, -0.1342, -0.6915, -0.0663,\n",
      "         -0.1502, -0.2964],\n",
      "        [ 0.6833,  0.3048, -0.2603, -0.5268,  0.9825,  0.3805, -0.5128, -0.0672,\n",
      "          0.3107,  0.5761],\n",
      "        [-0.0586,  0.6021, -0.4231,  0.2985,  0.9197,  0.2046, -0.5808,  0.6251,\n",
      "          0.2493, -0.0814],\n",
      "        [-0.6348,  0.4356,  0.4389, -0.0468,  0.3976,  0.5120, -0.3451, -0.7915,\n",
      "          0.2803,  0.6157],\n",
      "        [ 0.1593,  0.8556, -0.0638, -0.0517, -0.3296,  0.6732, -0.5104, -0.1356,\n",
      "          0.2565,  1.0267],\n",
      "        [ 0.1924,  0.1236,  0.9651, -0.8008,  0.6853,  0.1508, -0.2585,  0.3824,\n",
      "         -0.0353,  0.4625],\n",
      "        [-0.2881,  0.4693,  0.3446, -0.4070, -0.3797,  0.3500, -0.3912, -0.1755,\n",
      "          0.1874,  1.2784],\n",
      "        [ 0.1139,  0.4501,  0.0556,  0.1420,  0.0356,  0.8711, -0.2885, -0.4735,\n",
      "          0.6211,  1.1450],\n",
      "        [-0.0513,  0.7383,  0.2427, -0.0630, -0.1696,  1.1447, -0.1916, -0.3522,\n",
      "         -0.0912,  0.7376],\n",
      "        [ 0.2767,  0.8098, -0.1109,  0.5786, -0.0132,  0.5824, -0.2709, -0.1099,\n",
      "          0.9331,  0.8414],\n",
      "        [ 0.6103,  1.0838,  0.2933, -0.2477, -0.0418,  0.7177, -0.4520, -0.0664,\n",
      "          0.3990,  1.0999],\n",
      "        [-0.4810,  0.1159,  0.6623,  0.0821,  0.2999,  0.1748, -0.8111, -0.1653,\n",
      "          0.5092,  0.4103],\n",
      "        [-0.9765,  0.3845,  0.3570,  0.2834,  0.1330, -0.1082,  0.0678, -0.3097,\n",
      "          0.1300,  0.4967],\n",
      "        [ 0.4270,  0.4252,  0.7694,  0.1509, -0.3821,  0.6857, -0.6717, -0.4433,\n",
      "          0.4872,  0.9604],\n",
      "        [-0.3357,  0.9741,  0.1505, -0.4839, -0.2995,  0.7520, -0.4877, -0.9365,\n",
      "         -0.3991,  0.7330],\n",
      "        [-0.3213,  1.0567,  0.3418, -0.3903, -0.0224,  0.4207, -0.0449, -0.7486,\n",
      "          0.2537,  1.0014],\n",
      "        [-0.1929,  0.5905,  0.2843, -0.1994,  0.3605,  0.4785, -0.1627,  0.0663,\n",
      "          0.3506,  1.0171],\n",
      "        [-0.3021,  0.7539,  0.1222, -0.4191, -0.6722,  0.6906, -0.2835, -0.6444,\n",
      "         -0.0807,  1.1475],\n",
      "        [-0.0703,  0.7177,  0.9133,  0.2466,  0.0671,  0.3199, -0.6494, -0.2748,\n",
      "          0.0457,  0.9430],\n",
      "        [ 0.2202, -0.0906, -0.0700,  0.0706,  0.0117,  0.9961, -0.5547,  0.3100,\n",
      "          0.4799,  0.8911],\n",
      "        [ 0.3032, -0.0413,  0.1630, -0.3950,  0.0656,  0.6595, -0.5798, -0.0300,\n",
      "          0.7755,  0.8288],\n",
      "        [-0.3605,  0.4808,  0.3104,  0.1809, -0.3551, -0.0026, -0.7600, -0.6737,\n",
      "          0.4700,  0.7319],\n",
      "        [-0.2863,  0.0301,  1.0279, -0.5226,  0.4396,  0.5033, -0.6262, -0.6188,\n",
      "          1.0079,  0.5461]], device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "           7, -100, -100, -100, -100, -100, -100, -100,    4, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100,    3, -100, -100,    9, -100, -100, -100,\n",
      "           9, -100, -100,    0], device='cuda:3')\n",
      "field_name Use Chip\n",
      "nfeas 3\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[ 0.0568, -0.5343, -0.2870],\n",
      "        [ 0.0951, -1.7130,  0.0740],\n",
      "        [-0.2038, -0.8945,  0.1426],\n",
      "        [-0.2183, -0.3960, -1.0365],\n",
      "        [-0.3415, -1.2013, -0.6699],\n",
      "        [-0.2221, -1.2512, -0.5147],\n",
      "        [-0.1961, -1.6679, -0.1293],\n",
      "        [-0.6880, -0.6587, -0.2931],\n",
      "        [ 0.3950, -1.2233,  0.0466],\n",
      "        [-0.4622, -0.8245, -1.0293],\n",
      "        [-0.2803, -1.2588, -0.6859],\n",
      "        [-0.0372, -0.6284, -0.8089],\n",
      "        [-0.2309, -0.4109,  0.4326],\n",
      "        [-0.5932, -0.9744,  0.0466],\n",
      "        [-0.3439, -1.1774, -0.5985],\n",
      "        [ 0.0341, -0.9137, -0.4271],\n",
      "        [-0.5243, -1.0960, -0.0052],\n",
      "        [-0.3653, -0.7192, -0.2097],\n",
      "        [-0.5084, -0.8875,  0.0164],\n",
      "        [-0.3855, -1.0967, -0.0823],\n",
      "        [ 0.2253, -0.1175, -0.7091],\n",
      "        [ 1.0840,  0.4317, -1.4702],\n",
      "        [ 0.2654,  0.3656, -0.6381],\n",
      "        [ 0.6895, -0.3266, -0.9569],\n",
      "        [ 0.4848, -0.2782, -0.3744],\n",
      "        [ 0.9930,  0.1139, -1.0891],\n",
      "        [ 0.5745, -0.3981, -0.8184],\n",
      "        [-0.5569, -0.0430, -1.2643],\n",
      "        [ 0.3357, -0.5341, -0.4845],\n",
      "        [ 0.2692,  0.3213, -0.4940],\n",
      "        [ 0.3480,  0.1006, -1.1248],\n",
      "        [ 0.5847, -0.2954,  0.0727],\n",
      "        [ 0.8894, -0.2684, -1.1247],\n",
      "        [ 0.3749, -0.0840, -0.9164],\n",
      "        [ 0.2901, -0.2690, -0.6298],\n",
      "        [-0.2602,  0.3503, -1.4516],\n",
      "        [-0.5214, -0.6927, -0.2829],\n",
      "        [ 0.6106, -0.4230, -1.2107],\n",
      "        [ 0.7018,  0.1291, -1.0726],\n",
      "        [ 0.0651, -0.0064, -0.2285]], device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100,    0, -100, -100, -100,    0,    0, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100,    1, -100, -100, -100,    1,    1, -100,    1,    1,\n",
      "        -100, -100,    1, -100], device='cuda:3')\n",
      "field_name Merchant Name\n",
      "nfeas 4100\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[ 0.4822, -0.4330, -0.3461,  ..., -0.5488, -0.5921, -0.4491],\n",
      "        [ 0.5902, -0.2586, -0.2962,  ..., -0.0954, -1.2072, -0.2955],\n",
      "        [ 0.6445, -0.7291,  0.1310,  ..., -0.3443, -1.4010, -0.9536],\n",
      "        ...,\n",
      "        [ 0.3137,  0.4323, -0.4233,  ..., -0.5977,  0.0511, -0.1750],\n",
      "        [ 0.3601,  0.4595, -0.0333,  ..., -0.1546,  0.2023, -0.1165],\n",
      "        [ 0.1501,  0.4737, -0.0685,  ..., -0.3061, -0.3327, -0.3991]],\n",
      "       device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([   4, -100, -100, -100, -100, -100, -100, -100, -100,    0, -100, -100,\n",
      "         165, -100, -100, -100, -100, -100,   55, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100,   54, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "          15,   38, -100, -100], device='cuda:3')\n",
      "field_name Merchant City\n",
      "nfeas 2374\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[-0.1729, -0.3447, -0.5818,  ..., -0.2893, -0.6804, -0.3742],\n",
      "        [-0.2074, -0.2909, -0.9856,  ...,  0.4398, -1.0617, -0.7066],\n",
      "        [-0.1451, -0.2672, -0.8212,  ...,  0.0102, -0.7314, -1.1645],\n",
      "        ...,\n",
      "        [-0.0297,  0.1137, -0.2625,  ..., -0.2477,  0.2890, -0.7165],\n",
      "        [-0.0078,  0.1807,  0.1262,  ..., -0.2934,  0.5699,  0.2364],\n",
      "        [-0.3330,  0.1532, -0.0772,  ..., -0.5584,  0.2113, -0.4607]],\n",
      "       device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100,    1, -100, -100, -100, -100, -100, -100, -100,    1,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100,   18, -100, -100, -100, -100, -100,\n",
      "          18, -100, -100, -100], device='cuda:3')\n",
      "field_name Merchant State\n",
      "nfeas 98\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[-0.5939,  0.2990,  0.4144,  ..., -0.1991, -0.1135,  0.4019],\n",
      "        [-0.1649,  0.9493,  0.1362,  ..., -0.4199, -0.3413, -0.4388],\n",
      "        [-0.0597,  0.9718,  0.1178,  ...,  0.2791,  0.4502, -0.0703],\n",
      "        ...,\n",
      "        [-0.0481,  0.5580, -0.1412,  ..., -0.0627, -0.2233, -0.0686],\n",
      "        [-0.3911, -0.4281, -0.0724,  ...,  0.0668, -0.5977,  0.3228],\n",
      "        [ 0.5905,  0.1657, -0.5721,  ..., -0.0177, -0.4613, -0.3476]],\n",
      "       device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    2,\n",
      "           2, -100, -100,    2,    2, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100,    8, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100], device='cuda:3')\n",
      "field_name Zip\n",
      "nfeas 3899\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[ 0.2233, -0.3273,  0.3739,  ...,  0.1768, -0.3894, -0.1012],\n",
      "        [ 0.3410, -0.7759,  0.5655,  ..., -0.1217, -0.1367, -0.1430],\n",
      "        [-0.2147, -0.4558,  0.1011,  ..., -0.1785, -0.2105, -0.1069],\n",
      "        ...,\n",
      "        [ 0.6701, -0.2773, -0.6111,  ..., -0.3327, -0.0641,  0.1225],\n",
      "        [ 0.0649, -0.1951, -0.3154,  ...,  0.2988,  0.2222, -0.1756],\n",
      "        [ 1.2000, -0.0774,  0.1460,  ...,  0.0928,  0.3452, -0.0868]],\n",
      "       device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100,    1, -100, -100,    8, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,  127, -100,\n",
      "        -100, -100,   20, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100,   20, -100], device='cuda:3')\n",
      "field_name MCC\n",
      "nfeas 109\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[-0.1166,  0.3310,  0.2642,  ..., -0.6936, -0.0758, -0.6149],\n",
      "        [ 0.0096,  0.2252, -0.0679,  ..., -0.1843,  0.0146,  0.1264],\n",
      "        [ 0.3262,  0.6392,  0.6695,  ...,  0.3560, -0.1579, -0.9359],\n",
      "        ...,\n",
      "        [ 0.0056,  0.5290,  0.0811,  ...,  0.1279, -0.8198, -0.1531],\n",
      "        [-0.0083,  0.4008, -0.7304,  ...,  0.2115, -1.0430,  0.3313],\n",
      "        [-0.2005,  0.0670,  0.2861,  ..., -0.2423, -1.1331, -0.1558]],\n",
      "       device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100,    7, -100, -100, -100, -100, -100, -100,    9,\n",
      "        -100, -100, -100, -100,    1,    7,    8, -100, -100, -100, -100, -100,\n",
      "        -100, -100,    6, -100, -100,    6, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100], device='cuda:3')\n",
      "field_name Errors?\n",
      "nfeas 18\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[-1.3253e+00, -5.0528e-01,  2.6206e-01, -9.4556e-02, -3.3326e-01,\n",
      "          6.3352e-01,  6.2871e-01, -6.1215e-01,  2.9088e-01, -1.8907e-01,\n",
      "          2.2253e-02, -5.8852e-01, -7.6125e-01,  4.8009e-02,  8.8548e-01,\n",
      "         -7.6865e-01, -2.5828e-01, -6.4686e-01],\n",
      "        [-2.2579e-01, -1.1156e+00,  1.0428e+00, -7.7518e-01, -2.7960e-01,\n",
      "          1.5035e-01,  3.5679e-01,  2.8724e-01, -2.0650e-01,  3.9052e-01,\n",
      "          1.4146e-01, -4.8602e-01, -9.4567e-01,  1.4837e-01,  6.7986e-01,\n",
      "         -2.8834e-01,  3.3845e-01, -2.5721e-01],\n",
      "        [-7.0682e-02, -1.0178e+00, -2.9371e-01, -7.7522e-01, -1.0465e-01,\n",
      "          1.4273e-01,  3.7220e-01, -6.3212e-01,  2.9792e-01,  1.8067e-01,\n",
      "          9.2758e-02, -3.4249e-01, -9.2681e-01,  6.0481e-01,  2.5136e-01,\n",
      "         -1.1543e+00,  7.3050e-01, -1.6998e-01],\n",
      "        [-1.8636e-02, -8.9256e-01,  9.4285e-01, -3.2182e-01,  2.7654e-01,\n",
      "          1.5565e-01, -4.8038e-01, -3.2681e-01,  3.8153e-01,  2.7602e-01,\n",
      "         -1.9175e-01, -4.0606e-01, -1.1047e+00, -3.1451e-01,  6.9959e-01,\n",
      "         -5.9552e-01,  8.1099e-01, -3.2029e-02],\n",
      "        [ 4.7724e-02, -6.2504e-01,  4.1724e-01,  1.4336e-01, -2.4588e-01,\n",
      "          2.0366e-01, -5.5817e-02,  4.8496e-01,  1.5399e+00,  3.0246e-01,\n",
      "         -7.7781e-01, -5.3589e-01, -1.0775e+00, -3.7446e-03,  7.0913e-01,\n",
      "          5.5157e-02,  3.5362e-01,  8.4627e-03],\n",
      "        [ 2.9699e-01, -6.5265e-01, -1.9977e-01, -7.4421e-01,  6.1549e-01,\n",
      "          6.7374e-01,  1.4509e+00,  1.3278e-01,  6.0874e-01,  4.9038e-01,\n",
      "         -7.5238e-01, -6.5755e-01, -6.2249e-01,  4.0972e-01,  4.5685e-01,\n",
      "         -7.5539e-01,  1.0426e+00, -2.2789e-02],\n",
      "        [-1.8009e-01,  1.0225e-01,  2.2824e-01, -8.1077e-01,  5.0375e-01,\n",
      "         -5.0607e-02,  1.2981e-02, -5.7929e-01,  6.3828e-01,  1.4960e-01,\n",
      "         -4.1353e-01, -5.8509e-02, -9.1638e-01,  2.3080e-01,  3.9061e-01,\n",
      "         -1.2444e+00,  7.2135e-01,  1.3225e-01],\n",
      "        [ 1.2952e-01, -4.7297e-01,  7.4110e-02, -9.4622e-01,  2.5920e-01,\n",
      "          9.5427e-04,  6.4859e-01, -2.3298e-01,  5.4971e-01,  2.2399e-01,\n",
      "         -4.3136e-01, -3.4285e-01, -7.7969e-01, -2.6403e-01,  1.1173e+00,\n",
      "         -5.6671e-01,  7.5483e-01,  5.3511e-02],\n",
      "        [-9.3000e-02, -6.0338e-01,  2.2322e-01, -8.1954e-01, -1.2841e-01,\n",
      "          3.6571e-01,  4.8052e-01,  4.8834e-02, -1.6880e-01,  3.1277e-01,\n",
      "          2.0297e-01, -7.2518e-01, -5.4866e-01,  8.5614e-01,  4.9400e-01,\n",
      "         -8.3548e-01,  5.7109e-01, -1.1795e-02],\n",
      "        [-3.9658e-01, -2.5864e-01, -1.6937e-01, -9.2857e-01, -2.8643e-01,\n",
      "          6.4930e-01,  1.9677e-01,  2.5158e-02,  7.0518e-01, -2.8605e-01,\n",
      "          3.8152e-01, -9.6042e-01, -9.9365e-01,  2.3443e-01,  1.9233e-01,\n",
      "         -9.9771e-01,  5.9344e-01,  5.4700e-02],\n",
      "        [-3.4830e-01, -7.5677e-01,  3.3210e-01, -5.8892e-01,  1.9635e-01,\n",
      "          5.2208e-01, -7.1049e-02, -3.8124e-02,  6.1544e-01,  2.1975e-01,\n",
      "          3.3183e-01, -5.0457e-01, -1.0055e+00,  2.9671e-01,  1.5151e-01,\n",
      "         -1.3399e+00,  1.0867e+00, -8.3472e-02],\n",
      "        [-1.1590e-01, -8.6720e-01,  3.5245e-01, -2.1927e-01,  5.5301e-01,\n",
      "          1.9514e-01, -4.8718e-02, -3.2594e-01, -1.2525e-01, -3.2912e-01,\n",
      "          1.4446e-01, -1.6432e-01, -3.5921e-01,  1.9070e-01,  1.1979e-01,\n",
      "         -7.6317e-01,  1.1561e+00,  3.0013e-01],\n",
      "        [-2.0229e-01, -2.9033e-01,  9.5582e-01, -8.8993e-01, -5.7157e-01,\n",
      "          6.5005e-01,  1.7885e-01, -4.9352e-01, -2.7073e-01, -4.4808e-02,\n",
      "         -2.8189e-01, -6.7852e-01, -3.3783e-01, -3.3305e-01,  5.8721e-01,\n",
      "         -1.2104e+00,  6.1521e-01, -1.5872e-01],\n",
      "        [ 1.6248e-03, -8.0061e-01,  4.3584e-01, -3.8588e-01,  2.7103e-01,\n",
      "          4.8053e-01, -8.6763e-02, -6.4042e-01,  3.2301e-01, -1.0404e-01,\n",
      "          1.8360e-02, -2.6474e-01, -7.5760e-01,  2.0572e-02,  1.1040e-01,\n",
      "         -1.3605e+00,  9.3094e-01, -5.6849e-02],\n",
      "        [ 5.9771e-01, -1.0632e+00, -1.7309e-01, -8.0848e-01,  4.8643e-01,\n",
      "          2.1586e-01,  1.3678e+00, -3.7949e-01,  3.7272e-01,  5.2471e-01,\n",
      "         -1.7495e-01, -6.6027e-01, -9.5943e-01, -4.2200e-01,  2.9230e-01,\n",
      "         -1.2730e+00,  1.2367e+00, -1.3592e-01],\n",
      "        [ 3.4573e-01, -8.1204e-01,  9.0034e-01, -4.6051e-01,  6.1811e-02,\n",
      "          2.9004e-01,  2.2694e-02, -8.4975e-01,  6.1538e-01,  2.6039e-01,\n",
      "         -8.7344e-01, -7.7691e-01, -1.2333e+00, -6.0028e-01,  8.5379e-01,\n",
      "         -8.7437e-01,  5.3697e-01, -3.0644e-01],\n",
      "        [ 1.3502e-01, -1.0022e+00, -1.8643e-01, -7.5870e-01,  8.7223e-01,\n",
      "          4.2516e-01,  2.3775e-01, -2.3607e-01, -3.3521e-01, -3.0874e-01,\n",
      "          3.5247e-01, -3.4818e-01, -6.3777e-01,  4.0408e-01,  2.1262e-01,\n",
      "         -9.6668e-01,  6.4531e-01,  8.3176e-01],\n",
      "        [-2.0496e-01, -4.2989e-01,  5.1104e-01, -9.7206e-02,  4.6590e-01,\n",
      "         -1.1811e-01,  7.8737e-01, -4.9437e-01,  2.5307e-01, -1.9212e-01,\n",
      "          1.0871e-01, -5.5522e-01, -1.1908e+00,  7.5906e-01,  3.2557e-01,\n",
      "         -1.0836e+00,  5.6161e-01,  6.3619e-01],\n",
      "        [ 1.8221e-01, -7.5995e-01,  2.7414e-01, -8.8721e-01,  2.5290e-01,\n",
      "          5.3190e-01,  5.8565e-01, -8.3371e-01,  9.7364e-01, -2.6111e-01,\n",
      "         -1.0291e-01, -3.6379e-01, -7.2317e-01,  4.0818e-02,  3.1779e-01,\n",
      "         -7.9731e-01,  6.8373e-01, -4.3982e-01],\n",
      "        [ 4.0657e-02, -6.1451e-01, -1.9115e-01, -9.1502e-01,  2.7866e-01,\n",
      "          5.1094e-02,  1.9165e-01, -9.0587e-01,  5.3192e-02,  1.1145e-01,\n",
      "         -5.3684e-01, -5.5556e-01, -7.2038e-01,  2.6304e-01,  4.5255e-01,\n",
      "         -8.7368e-01,  5.9385e-01, -8.3228e-02],\n",
      "        [-3.7937e-01,  2.5498e-01, -1.8281e-01, -5.8628e-01, -4.1542e-01,\n",
      "          1.1234e-02,  2.2105e-02, -3.1033e-01, -9.7353e-01,  7.7079e-01,\n",
      "         -2.0063e-01,  3.7448e-01, -3.4796e-01,  1.6875e-02, -2.1120e-01,\n",
      "          1.1382e+00, -2.9921e-01,  1.5707e-01],\n",
      "        [-7.3277e-01,  5.6977e-02, -4.2711e-01, -6.8967e-01, -6.9251e-01,\n",
      "          5.3771e-01,  2.4173e-01, -1.5699e-02, -3.0816e-01,  4.5437e-02,\n",
      "         -4.8820e-01,  4.2509e-02, -2.7178e-01, -1.0536e-01, -4.2006e-02,\n",
      "          6.5349e-02, -3.9780e-01,  3.5723e-01],\n",
      "        [-9.8387e-01,  1.6317e-01,  5.3281e-01, -4.2962e-01, -3.8225e-01,\n",
      "          2.3407e-01, -6.4736e-01, -9.6037e-01, -3.7691e-02,  4.5448e-01,\n",
      "          2.1245e-01,  2.8560e-01,  8.5809e-02, -1.3715e-01, -1.0263e-01,\n",
      "         -2.1005e-01,  4.6968e-01,  9.5881e-01],\n",
      "        [ 2.2843e-01,  1.6664e-01, -4.6158e-01, -6.0769e-01, -2.2624e-01,\n",
      "          5.5710e-01,  6.2259e-01,  1.9277e-01,  1.2243e-01,  3.6802e-01,\n",
      "         -7.1877e-01,  6.1925e-02, -1.0396e+00, -3.8825e-01, -3.8695e-03,\n",
      "          2.1153e-01,  1.7005e-01,  4.0166e-01],\n",
      "        [-8.7365e-01,  8.7084e-01, -2.7968e-01, -5.4476e-01, -4.9776e-01,\n",
      "          5.4719e-01,  3.0742e-02,  3.8113e-02, -1.0248e+00,  5.4639e-01,\n",
      "         -5.9746e-01,  2.1866e-01, -5.9484e-01,  4.7923e-01, -1.2349e-01,\n",
      "         -3.9055e-03, -3.8232e-02,  8.3246e-01],\n",
      "        [-4.0914e-01, -9.2958e-02, -6.3658e-02, -5.7647e-01, -7.4118e-01,\n",
      "          5.6996e-01,  2.2074e-01, -6.7846e-01, -2.4130e-01,  4.2921e-01,\n",
      "         -4.4999e-01, -3.4881e-01, -4.4201e-01, -3.8130e-01,  2.5290e-01,\n",
      "          2.3192e-01, -2.8794e-01,  3.0252e-02],\n",
      "        [-8.6057e-01,  1.9548e-01,  2.9034e-01, -3.0111e-01, -3.3305e-01,\n",
      "          1.9307e-01, -4.1552e-01, -2.9695e-01,  1.1407e-01,  3.3626e-01,\n",
      "         -6.0613e-01,  2.3226e-01, -1.2144e-01,  5.1255e-01,  9.1805e-03,\n",
      "         -3.1832e-02, -7.4505e-02,  4.8810e-01],\n",
      "        [ 2.8426e-02,  7.6583e-02,  1.4552e-01, -1.0484e-01, -3.9364e-01,\n",
      "         -8.0669e-02, -3.1044e-01, -6.5936e-01, -4.2622e-01,  3.2476e-01,\n",
      "         -6.1900e-01,  1.8645e-02, -3.7657e-01, -6.3073e-01,  2.8711e-01,\n",
      "          2.7290e-01, -1.7028e-01,  6.6916e-01],\n",
      "        [-7.0936e-01,  2.4388e-01,  2.2241e-02, -9.7241e-01, -6.0352e-01,\n",
      "          2.7397e-01, -3.3323e-02, -4.5411e-01, -4.3703e-01,  4.6091e-01,\n",
      "         -3.6230e-01,  3.0134e-01, -5.2053e-01,  3.7492e-01, -3.5210e-01,\n",
      "          2.1848e-01, -1.7906e-01,  1.9002e-01],\n",
      "        [-4.0018e-01,  4.1804e-01,  1.7210e-01, -5.2321e-01, -4.3599e-01,\n",
      "          2.2712e-01,  6.1764e-01, -5.0974e-01, -2.5802e-01,  7.9496e-01,\n",
      "         -2.8838e-01,  4.6104e-01, -8.9381e-02, -7.9828e-02, -1.8936e-01,\n",
      "          8.5217e-01,  5.4250e-02, -1.7798e-01],\n",
      "        [-5.9222e-01, -1.4821e-01,  1.6070e-01, -4.3889e-01, -3.8535e-01,\n",
      "          7.8384e-01, -2.2209e-02,  9.7088e-02, -5.0720e-01,  7.4028e-02,\n",
      "         -2.7870e-01, -2.5099e-01, -7.7070e-01, -2.7004e-01, -1.1935e-01,\n",
      "          3.3616e-01, -3.9741e-01,  8.1676e-01],\n",
      "        [ 5.3004e-02,  1.3745e-01,  1.8640e-02, -5.7758e-01,  3.6106e-02,\n",
      "          5.1057e-01,  9.3317e-02,  4.9198e-01, -6.9212e-01,  2.0932e-01,\n",
      "         -8.1354e-01,  1.8416e-01, -3.4477e-01, -7.1966e-01, -4.5025e-01,\n",
      "          6.0263e-02, -1.2235e-01,  1.1501e+00],\n",
      "        [-1.9833e-01, -4.5172e-01, -2.6231e-01, -5.6177e-01, -5.1417e-01,\n",
      "          4.7343e-01, -1.3516e-01, -2.0966e-01, -8.2458e-01,  4.8771e-02,\n",
      "         -7.8056e-01, -4.8763e-01, -2.8090e-01,  1.3007e-01,  2.0385e-02,\n",
      "          8.3506e-01, -7.3736e-01,  4.5540e-01],\n",
      "        [-1.3791e-01, -5.5559e-01, -4.0152e-01, -3.0946e-01, -2.8252e-01,\n",
      "          6.8374e-01,  8.6500e-01,  5.5594e-02, -1.8003e-01,  2.7437e-01,\n",
      "         -7.2201e-01,  5.5831e-02, -6.1840e-01, -5.8573e-01, -3.6406e-01,\n",
      "          1.3422e-01, -1.7594e-01,  2.8310e-01],\n",
      "        [-1.0064e-01,  3.9991e-01, -4.4699e-02, -6.3261e-01, -1.9232e-01,\n",
      "          2.4579e-01,  4.8871e-01, -2.2104e-01, -8.1584e-02,  2.3735e-01,\n",
      "         -4.3412e-01,  1.8160e-01, -6.1917e-01, -5.0474e-01,  1.0797e-01,\n",
      "          2.2757e-01, -7.1140e-02,  7.9541e-01],\n",
      "        [ 8.9861e-03,  9.7173e-01,  2.8416e-01,  3.1008e-01, -5.5193e-01,\n",
      "         -2.2310e-01, -1.7782e-01, -7.3584e-01,  2.6950e-02,  3.3666e-01,\n",
      "         -4.4422e-01,  1.1033e-01, -6.0943e-02, -7.8077e-01,  5.4683e-01,\n",
      "          7.3921e-01,  1.4095e-01,  7.1412e-02],\n",
      "        [-1.0191e+00, -1.2873e-01,  6.7013e-01, -6.0969e-01, -2.0766e-01,\n",
      "          2.9857e-01,  2.1155e-01, -5.2282e-01, -6.3302e-02,  3.2365e-01,\n",
      "         -3.8413e-01, -3.6701e-01, -1.2569e+00, -7.4987e-02, -7.8453e-02,\n",
      "          2.3585e-02,  1.1013e-01,  4.2697e-01],\n",
      "        [-5.0663e-01,  2.8978e-01,  5.1997e-01, -6.1153e-02, -1.6403e-01,\n",
      "          3.0165e-01, -1.1712e-01,  9.4818e-03, -4.4220e-01,  5.8056e-01,\n",
      "          3.7236e-02, -2.8585e-01, -3.1190e-01, -7.2560e-01,  4.4758e-01,\n",
      "          4.3739e-01, -1.2846e-01,  5.2360e-01],\n",
      "        [-4.8474e-02,  3.0446e-01, -1.8960e-01,  1.0596e-01,  1.1638e-01,\n",
      "          5.6334e-01,  6.1906e-01, -4.7927e-01, -4.5286e-02,  4.8576e-01,\n",
      "         -3.8139e-01,  7.9248e-01, -2.1745e-01, -4.3333e-01, -2.4546e-01,\n",
      "          9.9182e-01,  4.9030e-02,  1.7149e-01],\n",
      "        [-1.2252e+00,  1.8067e-01, -7.6941e-01, -4.0724e-02, -5.1992e-01,\n",
      "          2.4192e-01,  5.9839e-01, -4.6437e-01, -8.7714e-01,  5.0144e-01,\n",
      "          1.3000e-01, -2.5878e-01, -1.0560e+00,  8.2913e-02, -5.6519e-01,\n",
      "          4.1703e-01, -7.8183e-02,  6.4618e-01]], device='cuda:3',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([   0, -100, -100, -100,    0,    0,    0, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100,    0, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    0,\n",
      "        -100, -100,    0, -100], device='cuda:3')\n",
      "field_name SPECIAL\n",
      "nfeas 7\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cuda:3\n",
      "Prediction score for loss - tensor([[ 0.0000e+00,  1.3996e-01, -7.4077e-01,  2.6764e-01, -4.6025e-01,\n",
      "         -2.7071e-01, -7.5925e-01],\n",
      "        [ 0.0000e+00,  2.1754e-01, -4.7660e-01, -6.7820e-01, -4.2174e-01,\n",
      "         -8.9275e-01, -6.9404e-01],\n",
      "        [ 0.0000e+00,  3.4810e-01,  1.3554e-01, -2.6513e-01, -5.7555e-01,\n",
      "         -3.0441e-01, -2.2898e-01],\n",
      "        [ 0.0000e+00,  1.2879e-01, -2.0365e-01, -2.4561e-01, -5.1641e-01,\n",
      "         -1.0238e-01, -9.2196e-01],\n",
      "        [ 0.0000e+00, -5.4730e-01, -4.2208e-01, -1.9268e-01,  1.8879e-01,\n",
      "         -7.1482e-01, -8.9157e-01],\n",
      "        [ 0.0000e+00,  4.0235e-01, -6.5987e-01, -3.5779e-02, -2.0330e-01,\n",
      "         -7.7721e-01, -7.6490e-01],\n",
      "        [ 0.0000e+00,  9.2674e-02, -4.5424e-01, -1.1046e-01, -4.5768e-02,\n",
      "         -4.4892e-01, -6.6450e-01],\n",
      "        [ 0.0000e+00,  9.1035e-02, -3.6028e-01, -9.4254e-01, -7.4738e-01,\n",
      "         -4.1157e-01, -3.9277e-01],\n",
      "        [ 0.0000e+00,  5.8171e-01, -1.1965e-02, -1.2477e+00, -6.1151e-01,\n",
      "         -1.6127e-01, -7.8593e-01],\n",
      "        [ 0.0000e+00,  6.7535e-02,  2.4383e-02, -2.9830e-01, -3.4286e-02,\n",
      "          1.6320e-01, -6.0411e-01],\n",
      "        [ 0.0000e+00,  1.7063e-01,  2.8258e-02,  1.6681e-01, -5.9931e-01,\n",
      "          8.5097e-02, -4.9312e-01],\n",
      "        [ 0.0000e+00,  6.7557e-01, -8.0187e-01, -1.8036e-01,  3.6135e-02,\n",
      "          1.0126e-01, -8.7341e-01],\n",
      "        [ 0.0000e+00, -3.2613e-01, -4.0203e-01, -2.9870e-01, -1.0565e+00,\n",
      "          1.2525e-01, -2.9358e-01],\n",
      "        [ 0.0000e+00,  3.2088e-01, -4.4084e-01, -3.0592e-01, -3.1544e-01,\n",
      "         -4.2443e-01, -7.5117e-01],\n",
      "        [ 0.0000e+00,  4.9591e-01, -4.6808e-01,  3.9920e-02, -4.0121e-01,\n",
      "         -5.6684e-01, -5.9955e-01],\n",
      "        [ 0.0000e+00,  1.7589e-01, -2.3360e-01, -4.0085e-01, -7.0736e-01,\n",
      "         -7.1426e-01, -6.2449e-01],\n",
      "        [ 0.0000e+00, -1.2177e-01, -7.7055e-01, -5.6944e-01, -1.0971e+00,\n",
      "          9.5975e-02, -4.2059e-01],\n",
      "        [ 0.0000e+00,  3.0670e-01, -8.3145e-01, -4.3875e-01, -5.5263e-02,\n",
      "         -3.6797e-01, -1.0223e+00],\n",
      "        [ 0.0000e+00,  2.5211e-01,  3.4229e-02, -2.5446e-01, -7.5203e-01,\n",
      "         -5.2663e-01, -7.0144e-01],\n",
      "        [ 0.0000e+00, -1.2770e-01, -5.4932e-01,  2.2062e-01, -9.5240e-01,\n",
      "         -9.6036e-01, -8.1325e-01],\n",
      "        [ 0.0000e+00, -4.1702e-01, -2.2048e-01, -1.3733e+00, -4.5357e-01,\n",
      "         -1.8429e-01, -6.9743e-01],\n",
      "        [ 0.0000e+00, -4.4308e-01, -2.3565e-01, -1.2663e+00, -1.6112e-01,\n",
      "          1.7423e-01, -3.1206e-01],\n",
      "        [ 0.0000e+00, -3.8461e-01,  1.2820e-01, -1.4403e+00, -5.8655e-02,\n",
      "         -1.0208e+00, -8.0306e-01],\n",
      "        [ 0.0000e+00, -3.0821e-01,  4.5098e-02, -1.1372e+00, -4.9817e-01,\n",
      "          1.5109e-01, -4.7054e-01],\n",
      "        [ 0.0000e+00, -4.5454e-02, -1.2498e+00, -9.7233e-01, -1.1047e-03,\n",
      "         -4.7712e-01, -9.9146e-01],\n",
      "        [ 0.0000e+00, -3.1902e-01,  1.0718e-01, -1.2168e+00, -3.8656e-01,\n",
      "         -3.1017e-01, -2.0402e-01],\n",
      "        [ 0.0000e+00,  3.6019e-01, -4.8260e-01, -1.1621e+00, -7.3076e-01,\n",
      "         -2.8423e-01, -4.7141e-01],\n",
      "        [ 0.0000e+00, -1.1796e-01, -2.0747e-01, -1.7111e+00, -6.7628e-01,\n",
      "          2.7726e-02, -5.4692e-01],\n",
      "        [ 0.0000e+00,  2.2286e-01, -7.7363e-01, -1.1146e+00, -4.4001e-01,\n",
      "         -1.8476e-01, -6.6760e-01],\n",
      "        [ 0.0000e+00,  8.4474e-02,  3.1586e-02, -1.1867e+00, -7.1771e-01,\n",
      "         -2.1188e-01,  8.6392e-02],\n",
      "        [ 0.0000e+00,  1.1045e-01,  1.0359e-01, -1.2864e+00, -4.1140e-01,\n",
      "         -3.2232e-01, -7.8092e-01],\n",
      "        [ 0.0000e+00, -2.0079e-01,  1.6446e-01, -1.7055e+00, -1.1362e+00,\n",
      "          1.3886e-01,  1.3734e-02],\n",
      "        [ 0.0000e+00, -6.5446e-02, -3.3112e-01, -1.5052e+00, -8.7209e-01,\n",
      "         -1.2156e-01, -1.5291e-01],\n",
      "        [ 0.0000e+00, -4.2682e-01, -1.4607e-01, -1.6857e+00,  1.8273e-03,\n",
      "          1.2304e-02, -6.6856e-01],\n",
      "        [ 0.0000e+00, -2.9613e-01,  6.0272e-02, -1.2981e+00, -2.2325e-01,\n",
      "         -3.6381e-01, -3.0216e-01],\n",
      "        [ 0.0000e+00,  2.8708e-01, -2.4875e-01, -1.2299e+00, -8.3278e-01,\n",
      "         -2.6129e-01, -4.4553e-01],\n",
      "        [ 0.0000e+00, -3.2911e-02,  2.5084e-03, -1.3826e+00,  2.0979e-01,\n",
      "         -3.2116e-01, -6.2654e-01],\n",
      "        [ 0.0000e+00, -1.4967e-02,  4.3194e-01, -1.0898e+00, -4.2751e-01,\n",
      "         -7.1641e-01, -4.6748e-01],\n",
      "        [ 0.0000e+00,  1.5525e-02, -6.9856e-01, -6.4112e-01, -1.9757e-02,\n",
      "         -8.8406e-01, -5.2349e-01],\n",
      "        [ 0.0000e+00, -5.7430e-01, -3.1825e-01, -1.7370e+00, -6.1363e-02,\n",
      "          3.1138e-04, -1.1235e+00]], device='cuda:3', grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100], device='cuda:3')\n",
      "(tensor(nan, device='cuda:3', grad_fn=<AddBackward0>), tensor([[[ 0.0000,  0.3799,  0.7735,  ...,  0.2119,  0.3246, -0.7427],\n",
      "         [ 0.0000, -0.6503, -0.3309,  ..., -1.0369,  0.8308, -0.0548],\n",
      "         [ 0.0000,  0.3216,  0.4799,  ..., -0.1769,  0.3132,  0.8430],\n",
      "         ...,\n",
      "         [ 0.0000,  0.7354,  0.8948,  ..., -0.0099,  0.1585,  0.0085],\n",
      "         [ 0.0000,  0.1356, -0.0454,  ..., -0.0832, -0.3462,  0.4777],\n",
      "         [ 0.0000, -0.1277, -0.5493,  ...,  1.0087,  0.3121,  0.0300]],\n",
      "\n",
      "        [[ 0.0000,  0.6572,  0.6215,  ..., -0.7881,  0.1652,  0.5083],\n",
      "         [ 0.0000, -0.6349, -0.4634,  ..., -0.4777, -0.2143, -0.3288],\n",
      "         [ 0.0000, -0.5080, -0.1261,  ..., -0.2080,  0.3554,  0.1527],\n",
      "         ...,\n",
      "         [ 0.0000,  0.3881, -0.1802,  ..., -0.2013, -0.1213,  0.1235],\n",
      "         [ 0.0000, -0.5399,  0.3570,  ...,  0.6462,  0.3933,  0.8642],\n",
      "         [ 0.0000, -0.5743, -0.3182,  ...,  1.4767, -0.4739,  0.9545]]],\n",
      "       device='cuda:3', grad_fn=<ViewBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "for inps in tqdm(train_dataloader):\n",
    "    #print(inps.keys())\n",
    "    #print(inps['input_ids'].shape)\n",
    "    #print(inps['masked_lm_labels'].shape)\n",
    "    #print(inps['masked_lm_labels'], )\n",
    "    optim.zero_grad()\n",
    "    #print(inps['input_ids'].shape)\n",
    "    labels = inps.pop(\"Ouput\")\n",
    "    model.train()\n",
    "    inps['input_ids'] = inps['input_ids'].to('cuda:3')\n",
    "    inps['masked_lm_labels'] = inps['masked_lm_labels'].to('cuda:3')\n",
    "    outputs =model(**inps)\n",
    "    print(outputs)\n",
    "    break\n",
    "    loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    #print(loss)\n",
    "    # print(len(aa))\n",
    "    # print(\"Length of out - \", len(out))\n",
    "    # print('Ouput -', out[0].shape)\n",
    "    # #print('Ouput -', out[1].shape)\n",
    "    # print(aa[0])\n",
    "    # print(aa[1].shape)\n",
    "    # #aa.last_hidden_state\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "sam1 = torch.rand((40, 1))\n",
    "sam2 = torch.rand((40, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43msam1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msam2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:1159\u001b[0m, in \u001b[0;36mCrossEntropyLoss.__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m   1158\u001b[0m              reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index \u001b[38;5;241m=\u001b[39m ignore_index\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m=\u001b[39m label_smoothing\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:25\u001b[0m, in \u001b[0;36m_WeightedLoss.__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_WeightedLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m, weight)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight: Optional[Tensor]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:18\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28msuper\u001b[39m(_Loss, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction \u001b[38;5;241m=\u001b[39m reduction\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/_reduction.py:35\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mand\u001b[39;00m reduce:\n\u001b[1;32m     36\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m reduce:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "CrossEntropyLoss(sam1, sam2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(total_loss/len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('new_mode1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "#                                   vocab=vocab,\n",
    "#                                   field_ce=config['field_ce'],\n",
    "#                                   flatten=config['flatten'],\n",
    "#                                   ncols=dataset.ncols,\n",
    "#                                   field_hidden_size=config['field_hs']\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model.save_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_val = torch.load('new_mode1/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model = tab_net.model.tb_model.from_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(tab_net.model.tb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model.bert.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-23c5aa56e56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_classifier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlstm_classfr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_classfr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import models.lstm_classifier as lstm_classfr\n",
    "reload(lstm_classfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_fe_model = tab_net.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = lstm_classfr.LSTM(emb_inp_size=1062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_cls = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, custom_special_tokens,\n",
    "                 vocab,\n",
    "                 field_ce,\n",
    "                 flatten,\n",
    "                 ncols,\n",
    "                 field_hidden_size,\n",
    "                 bert_feature_size,\n",
    "                 base_model\n",
    "                 ):\n",
    "        super(Classifier, self).__init__()\n",
    "        '''\n",
    "        self.tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                        vocab=vocab,\n",
    "                                        field_ce=field_ce,\n",
    "                                        flatten=flatten,\n",
    "                                        ncols=ncols,\n",
    "                                        field_hidden_size=field_hidden_size)\n",
    "        '''\n",
    "        loaded_val = torch.load('new_mode1/pytorch_model.bin')\n",
    "        base_model.load_state_dict(loaded_val)\n",
    "        #print(base_model)\n",
    "        for p in base_model.parameters():\n",
    "            p.requires_grad = True\n",
    "        self.field_transformer = base_model.tab_embeddings\n",
    "        self.bert = base_model.tb_model\n",
    "        \n",
    "\n",
    "\n",
    "        self.classifier = lstm_classfr.LSTM(emb_inp_size=bert_feature_size)\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids ,input_args):\n",
    "        field_embeddings = self.field_transformer(input_ids)\n",
    "        #input_args['input_ids'] = input_ids\n",
    "        bert_features = self.bert(inputs_embeds=field_embeddings, **input_args)\n",
    "        \n",
    "        bert_features = bert_features[1]\n",
    "        print(bert_features.shape)\n",
    "        bert_features = bert_features.reshape((50, 20, 11, 8721))\n",
    "        bert_features = bert_features.reshape((50, 220, 8721))\n",
    "        cls_out = self.classifier(bert_features, T.as_tensor(([11])))\n",
    "        \n",
    "        return cls_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = Classifier(custom_special_tokens,\n",
    "                 vocab=vocab,\n",
    "                    field_ce=config['field_ce'],\n",
    "                    flatten=config['flatten'],\n",
    "                    ncols=dataset.ncols,\n",
    "                    field_hidden_size=config['field_hs'],\n",
    "                 bert_feature_size=8721, base_model=model)\n",
    "classif = classif.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.tb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([232])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as T\n",
    "T.as_tensor(([232]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_fn = torch.optim.Adadelta(params=classif.parameters(), lr=0.1, rho=0.95, eps=1e-08)\n",
    "loss_fn = T.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'masked_lm_labels', 'Ouput'])\n",
      "torch.Size([50, 220, 8721])\n",
      "inp_shaep torch.Size([50, 220, 8721])\n",
      "Before fc torch.Size([1, 256])\n",
      "After fc torch.Size([1, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-92acd7c26510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked_lm_labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked_lm_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclassif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-b9c2b773b164>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_args)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mbert_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8721\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mbert_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8721\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcls_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/murugesh/Clinical-Transformer/models/lstm_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp_emb, inp_len)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#text_fea = torch.squeeze(text_fea, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After fc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_fea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtext_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_fea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "for inps in train_dataloader:\n",
    "    print(inps.keys())\n",
    "    input_ids = inps.pop('input_ids')\n",
    "    out = inps.pop('Ouput')\n",
    "    classif.train()\n",
    "    \n",
    "    #print(out)\n",
    "    #print(input_ids.shape)\n",
    "    #print(inps['masked_lm_labels'].shape)\n",
    "    #print(inps['masked_lm_labels'], )\n",
    "    #print(inps[0].shape)\n",
    "    #print(inps[1].shape)\n",
    "    input_ids = input_ids.to('cuda:3')\n",
    "    inps['masked_lm_labels'] = inps['masked_lm_labels'].to('cuda:3')\n",
    "    preds =classif(input_ids, inps)\n",
    "    print(preds)\n",
    "    preds = preds.view(preds.size(0))\n",
    "    loss = loss_fn(preds.float(), out.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Class out - {class_out.shape}\")\n",
    "    print(class_out)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. append classifier with bert\n",
    "2. Freeze bert model after first train\n",
    "3. Use bert model and train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = T.nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(hn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(hn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

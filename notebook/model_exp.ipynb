{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import define_main_parser\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "#from dataset.prsa import PRSADataset\n",
    "from data.card import TransactionDataset\n",
    "#from models.modules import TabFormerBertLM\n",
    "from models import modules\n",
    "from models import tabformer_bert\n",
    "from scripts.utils import random_split_dataset\n",
    "#from data.datacollator import TransDataCollatorForLanguageModeling\n",
    "import data.datacollator as datacoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.tabformer_bert' from '/Users/murugesan.vadivel/DEV/works/Clinical-Transformer/notebook/../models/tabformer_bert.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(datacoll)\n",
    "reload(modules)\n",
    "reload(tabformer_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "config = vars(Namespace(cached=False, checkpoint=0, data_extension='', data_fname='card_transaction.v2', data_root='./data/credit_card/', data_type='card', do_eval=False, do_train=True, field_ce=True, field_hs=64, flatten=False, jid=1, lm_type='bert', log_dir='sam/logs', mlm=True, mlm_prob=0.15, nrows=None, num_train_epochs=3, output_dir='sam', save_steps=500, seed=9, skip_user=False, stride=5, user_ids=None, vocab_file='vocab.nb'))\n",
    "config['data_root'] = \"../dataset/credit_card/\"\n",
    "config['output_dir'] = \"sample\"\n",
    "config['log_dir'] = \"sample/logs\"\n",
    "makedirs(config['output_dir'], exist_ok=True)\n",
    "makedirs(config['log_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config['seed']\n",
    "random.seed(seed)  # python\n",
    "np.random.seed(seed)  # numpy\n",
    "torch.manual_seed(seed)  # torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)  # torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 21.37it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.08it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  8.27it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TransactionDataset(root=config['data_root'],\n",
    "                            fname=config['data_fname'],\n",
    "                            fextension=\"\",\n",
    "                            vocab_dir=config['output_dir'],\n",
    "                            nrows=None,\n",
    "                            user_ids=None,\n",
    "                            seq_len=20,\n",
    "                            mlm=True,\n",
    "                            cached=config['cached'],\n",
    "                            stride=10,\n",
    "                            flatten=config['flatten'],\n",
    "                            return_labels=True,\n",
    "                            skip_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/xqg2bpnj0bj0pdv44sb5k8m40000gp/T/ipykernel_25927/3874821253.py:3: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return_data2 = (return_data, torch.tensor(dataset.labels[20], dtype=torch.long))\n"
     ]
    }
   ],
   "source": [
    "return_data = torch.tensor(dataset.data[20], dtype=torch.long)\n",
    "return_data = torch.tensor(dataset.data[20], dtype=torch.long).reshape(dataset.seq_len, -1)\n",
    "return_data2 = (return_data, torch.tensor(dataset.labels[20], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [return_data2 for _ in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7801/2528551595.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labs = [torch.tensor(e[1], dtype=torch.long) for e in b]\n"
     ]
    }
   ],
   "source": [
    "labs = [torch.tensor(e[1], dtype=torch.long) for e in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lengths: train [25447]  valid [8483]  test [8483]\n",
      "# lengths: train [0.60]  valid [0.20]  test [0.20]\n"
     ]
    }
   ],
   "source": [
    "vocab = dataset.vocab\n",
    "custom_special_tokens = vocab.get_special_tokens()\n",
    "\n",
    "totalN = len(dataset)\n",
    "totalN = len(dataset)\n",
    "trainN = int(0.6 * totalN)\n",
    "\n",
    "valtestN = totalN - trainN\n",
    "valN = int(valtestN * 0.5)\n",
    "testN = valtestN - valN\n",
    "lengths = [trainN, valN, testN]\n",
    "print(f\"# lengths: train [{trainN}]  valid [{valN}]  test [{testN}]\")\n",
    "print(\"# lengths: train [{:.2f}]  valid [{:.2f}]  test [{:.2f}]\".format(trainN / totalN, valN / totalN,\n",
    "                                                                               testN / totalN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset, test_dataset = random_split_dataset(dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['flatten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = modules.TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "collactor_cls = \"TransDataCollatorForLanguageModeling\"\n",
    "data_collator = datacoll.TransDataCollatorForLanguageModeling(\n",
    "        tokenizer=tab_net.tokenizer, mlm=True, mlm_probability=config['mlm_prob']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=2,\n",
    "            collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#         output_dir=config['output_dir'],  # output directory\n",
    "#         num_train_epochs=config['num_train_epochs'],  # total number of training epochs\n",
    "#         logging_dir=config['log_dir'],  # directory for storing logs\n",
    "#         save_steps=config['save_steps'],\n",
    "#         do_train=config['do_train'],\n",
    "#         # do_eval=args.do_eval,\n",
    "#         # evaluation_strategy=\"epoch\",\n",
    "#         prediction_loss_only=True,\n",
    "#         overwrite_output_dir=True,\n",
    "#         # eval_steps=10000\n",
    "#     )\n",
    "# trainer = Trainer(\n",
    "#         model=tab_net.model,\n",
    "#         args=training_args,\n",
    "#         data_collator=data_collator,\n",
    "#         train_dataset=train_dataset,\n",
    "#         eval_dataset=eval_dataset,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tab_net.model\n",
    "#model = model.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = {'betas': (0.9, 0.999), 'eps': 1e-08, 'lr': 5e-05}\n",
    "optim = torch.optim.AdamW(model.parameters(), **optim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'masked_lm_labels', 'Ouput'])\n"
     ]
    }
   ],
   "source": [
    "for inps in train_dataloader:\n",
    "    print(inps.keys())\n",
    "    inps['masked_lm_labels'] = torch.clone(inps['input_ids'])\n",
    "    #print(inps['input_ids'] == inps['masked_lm_labels'])\n",
    "    #print(inps['Ouput'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12724 [00:00<?, ?it/s]/Users/murugesan.vadivel/DEV/works/Clinical-Transformer/notebook/../data/datacollator.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labs = [torch.tensor(e[1], dtype=torch.long) for e in examples]\n",
      "/Users/murugesan.vadivel/DEV/works/Clinical-Transformer/notebook/../data/datacollator.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples = [torch.tensor(e[0], dtype=torch.long) for e in examples]\n",
      "  0%|          | 0/12724 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Input Args - dict_keys(['masked_lm_labels'])\n",
      "Last Hidden State shape torch.Size([2, 20, 704])\n",
      "Sequence Output shape - torch.Size([2, 20, 704])\n",
      "Output shape - [2, 20, 704]\n",
      "Expected shape - [2, 220, -1]\n",
      "Sequence output - torch.Size([2, 220, 64])\n",
      "Masked lm labels - torch.Size([2, 220])\n",
      "field_name Card\n",
      "nfeas 8\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[-0.0549,  0.0804, -0.7153, -0.1201, -0.0160, -0.7906, -0.5682,  0.5449],\n",
      "        [ 0.4355,  0.2159, -0.2793, -0.3830,  0.9829, -1.2530, -0.0914,  0.5246],\n",
      "        [-0.2062, -0.0431,  0.1171,  0.3035,  0.6752, -0.4809,  0.1234,  0.3092],\n",
      "        [ 0.2080,  0.3912, -0.3714, -0.0330,  0.2237, -0.2571, -0.3521, -0.0735],\n",
      "        [-0.0517,  0.4988, -0.4331, -0.1777,  0.7124, -0.1401,  0.0781, -0.2243],\n",
      "        [ 0.0710,  0.2062, -0.4575, -0.2026,  0.4672, -0.8382, -0.3489,  0.7607],\n",
      "        [ 0.2148,  0.4205, -0.3505,  0.1466,  0.3609, -0.3331,  0.4778,  0.1846],\n",
      "        [-0.3450,  0.2423, -0.6865, -0.1948,  0.4426, -1.0252, -0.5083,  0.0514],\n",
      "        [ 0.6555,  0.1140, -0.1860, -0.2176,  0.8090, -0.9071, -0.2902, -0.3366],\n",
      "        [-0.3077,  0.0442, -0.2224, -0.0656,  0.3426, -0.8033, -0.2583,  0.4855],\n",
      "        [ 0.3410,  0.8534, -0.2800, -0.2316,  0.4301, -0.8085, -0.4267, -0.2602],\n",
      "        [-0.1174,  0.7364, -1.1832, -0.1939,  0.7060, -1.1040, -0.3339, -0.3397],\n",
      "        [ 0.1543,  0.7513, -0.5060, -0.3483,  0.8118, -0.6521, -0.3873,  0.4240],\n",
      "        [ 0.0365,  0.3218, -0.3361, -0.2373,  0.0702, -0.8225, -0.0977,  0.3897],\n",
      "        [ 0.9439,  0.8484, -0.4113,  0.3918,  1.1871, -0.5342,  0.0186,  0.4315],\n",
      "        [ 1.0034,  1.0668, -0.0700, -0.1559,  1.5188, -0.1589,  0.2696, -0.0676],\n",
      "        [-0.8006, -0.2689, -0.4564, -0.1358,  0.8430, -0.3817, -0.4707,  0.3910],\n",
      "        [-0.2289,  0.1133,  0.1808,  0.3250,  1.1778, -1.0143,  0.3786,  0.3232],\n",
      "        [ 0.8719,  0.4609, -0.3681, -0.7024,  0.3217, -0.7582, -0.4348, -0.6030],\n",
      "        [-0.5489,  0.0191, -0.3611, -0.7250,  0.4500, -0.6175,  0.2752,  0.5088],\n",
      "        [ 1.0881,  1.1934,  0.6649, -0.3093,  0.0987, -0.8849,  0.1812,  0.6312],\n",
      "        [ 0.7192,  0.9757,  0.2084, -0.4589,  0.3512, -0.7537, -0.3732, -0.1395],\n",
      "        [-0.8387,  0.1902,  0.6013, -0.6558,  0.3954, -0.4216, -0.4027,  0.8943],\n",
      "        [ 1.0620,  0.6142,  0.5329, -0.1838,  0.0570, -0.7740,  0.1322,  0.5376],\n",
      "        [ 0.9787,  1.0208,  0.2701, -0.4202,  0.3691, -0.6037, -0.3000,  0.5643],\n",
      "        [ 0.8714,  1.2459,  0.9169, -0.3532,  0.4762, -1.1809,  0.1530,  0.7024],\n",
      "        [ 1.3884,  0.7680,  0.7876, -0.1738,  0.4729, -0.4729,  0.0511,  0.7819],\n",
      "        [ 0.7558,  0.4590,  0.9399, -0.4480,  0.4229, -1.0665, -0.0835,  0.6734],\n",
      "        [ 1.2943,  1.2488,  0.6206, -0.3773,  0.5011, -0.8817, -0.0484,  0.3957],\n",
      "        [ 0.4428,  0.4612, -0.0377, -0.0946, -0.5987, -0.8710,  0.0212,  0.9664],\n",
      "        [ 1.1025,  0.5734,  0.0331, -0.1472,  0.2217, -0.2313,  0.0257, -0.1909],\n",
      "        [ 0.6554,  0.9851,  0.3749, -0.4978,  0.3243, -0.6230,  0.1722,  0.1500],\n",
      "        [ 0.8132,  1.1508,  0.4292, -0.0342,  0.1128, -0.4272, -0.1196, -0.0818],\n",
      "        [ 1.1177,  1.0077,  0.6803, -0.4463,  0.7016, -0.6207,  0.0715,  0.5195],\n",
      "        [ 0.7476,  1.1002,  0.2913, -0.6098,  0.3381, -0.7537,  0.0717,  0.2656],\n",
      "        [ 0.4524,  0.8807,  0.6025, -0.2612,  0.5500, -1.2911, -0.0211,  0.4289],\n",
      "        [ 1.1387,  0.5085, -0.0046,  0.2968, -0.7629, -0.9780,  0.0549, -0.1558],\n",
      "        [ 0.6801,  0.3464,  0.1781,  0.1235, -0.1041, -0.6443, -0.1533,  0.7755],\n",
      "        [ 0.2478,  1.5688,  0.7779, -1.1888,  0.5024, -0.4420,  0.2588, -0.2541],\n",
      "        [ 0.5901,  0.8379,  0.3105, -0.1840, -0.4056, -1.2970,  0.0914,  0.1148]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100,    0,    0, -100, -100, -100,    0,    0,\n",
      "        -100, -100,    0, -100, -100, -100, -100,    0, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100,    5, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n",
      "field_name Timestamp\n",
      "nfeas 10\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[-0.3044,  0.2162,  0.1273, -0.2756,  0.0395, -0.0239,  0.1569,  0.2401,\n",
      "         -0.7969,  0.5899],\n",
      "        [-1.0257, -0.3831,  0.5485,  0.0617,  0.6458,  0.0284, -0.8259, -0.0073,\n",
      "         -0.5261,  0.0509],\n",
      "        [-0.7261, -0.6388,  0.8185, -0.5846,  0.6728, -0.0039,  0.3336,  0.0859,\n",
      "         -0.2393, -0.0313],\n",
      "        [-0.3786, -0.0434,  0.2645, -0.0866,  0.0488,  0.4172, -0.2289,  0.4953,\n",
      "         -0.8482,  0.5260],\n",
      "        [ 0.1229,  0.3852, -0.1619,  0.2091, -0.0938,  0.0224, -0.2527,  0.3543,\n",
      "         -0.4005,  0.2467],\n",
      "        [-0.0812, -0.3882,  0.5175, -0.1191,  0.4609,  0.9480, -0.9585,  0.7564,\n",
      "         -0.1802, -0.0085],\n",
      "        [-0.6149, -0.7209,  0.8401,  0.2908,  0.3671,  0.5681, -0.6976,  0.1853,\n",
      "          0.0652,  0.5384],\n",
      "        [-0.3778, -0.3230,  0.2646,  0.0104, -0.2606,  0.6388, -0.2825,  0.4857,\n",
      "         -0.7030, -0.1966],\n",
      "        [-0.0902,  0.0037,  0.4246, -0.6395, -0.0567,  0.8188,  0.1069,  0.5698,\n",
      "         -0.3723,  0.4281],\n",
      "        [-0.4471, -0.3741,  0.5660, -0.0350, -0.5548,  0.4307,  0.2103,  0.3686,\n",
      "          0.3743, -0.2113],\n",
      "        [-0.2571, -0.4466,  0.4062,  0.3406,  0.6990,  0.5850, -0.6466,  0.7028,\n",
      "         -0.2579,  0.1070],\n",
      "        [ 0.0282,  0.1711,  0.1874,  0.2482,  0.2467,  1.1898, -0.3094,  0.2634,\n",
      "         -0.3714,  0.3459],\n",
      "        [ 0.3071,  0.2586, -0.4018,  0.3289, -0.2545,  0.4014, -0.1005,  0.1873,\n",
      "         -0.1318,  0.4192],\n",
      "        [-1.6758, -0.4041,  0.1599,  0.2096,  0.3580,  0.4906, -0.1590,  0.5059,\n",
      "         -0.3333, -0.2509],\n",
      "        [-0.4303, -0.4289,  0.3840, -0.0505,  0.1696,  0.5395, -0.4684,  0.4457,\n",
      "         -0.1831, -0.0797],\n",
      "        [-0.3048, -0.4003,  0.5074, -0.4953,  0.3472,  0.1214,  0.1730, -0.0871,\n",
      "         -0.9523, -0.0808],\n",
      "        [ 0.3701, -0.0528,  0.2796, -0.1580,  0.0646,  0.2601, -0.2583,  0.3625,\n",
      "         -0.7394,  0.2391],\n",
      "        [-0.3629, -0.1519,  0.1914,  0.1789, -0.0629, -0.2006,  0.4810,  0.0320,\n",
      "          0.5623, -0.0689],\n",
      "        [ 0.0892, -0.1300,  0.3090, -0.2202,  0.3584,  0.6602,  0.0536,  0.6693,\n",
      "         -1.1243,  0.2302],\n",
      "        [-0.7318, -0.4276,  0.2629, -0.3250,  0.2096, -0.1577, -0.2889,  0.6744,\n",
      "         -0.4699,  0.1901],\n",
      "        [-0.9551,  0.1073, -0.0686, -0.0686, -0.7619,  0.3030,  1.0232,  0.0042,\n",
      "          0.2525,  0.0335],\n",
      "        [-1.2046, -0.1572,  0.0133, -0.5735, -0.3782,  0.3009,  0.6046, -0.0155,\n",
      "          0.0749,  0.5835],\n",
      "        [-0.2270, -0.4493,  0.8763, -0.3478, -0.1285,  1.0189,  0.1786, -0.8657,\n",
      "          0.6402,  0.6403],\n",
      "        [-0.7720, -0.5810, -0.3892, -0.5309,  0.1674,  0.5447,  0.8161,  0.0939,\n",
      "          0.0703, -0.0106],\n",
      "        [-0.5647, -0.4308,  0.1078,  0.0872, -0.0282,  0.6882, -0.2197,  0.5307,\n",
      "          0.1660,  0.1900],\n",
      "        [-1.1104, -0.1018,  0.5589, -0.4566, -0.4381, -0.2102,  0.0306,  0.0497,\n",
      "         -0.2978,  0.3040],\n",
      "        [-0.8779, -0.5878, -0.5497, -0.6971, -0.3527, -0.0841,  0.7290,  0.6511,\n",
      "         -0.1643,  0.1952],\n",
      "        [-0.0487, -0.1717, -0.3263,  0.0499, -0.3182,  0.3969, -0.1533,  1.1025,\n",
      "          0.7377,  0.4545],\n",
      "        [-0.5923, -0.2626, -0.8331, -0.4382, -0.4310,  0.5300,  0.8474,  0.5097,\n",
      "          0.4321,  0.3422],\n",
      "        [-0.3693, -0.7937,  0.0060, -0.5747, -0.4394,  0.1052,  0.1297,  0.3658,\n",
      "          0.1491,  0.0509],\n",
      "        [-0.9204, -0.0864, -0.2735, -0.4672,  0.0028,  0.3190,  0.4153,  0.5984,\n",
      "          0.1144,  0.3443],\n",
      "        [-0.4112, -0.2492, -0.3417, -0.3030, -0.0575,  0.7647,  0.5096,  0.8283,\n",
      "          0.6099,  0.4192],\n",
      "        [-1.5114, -0.2205, -0.5161, -0.7634, -0.3871, -0.1760,  0.7443,  0.6033,\n",
      "         -0.1609, -0.0073],\n",
      "        [-0.3138, -0.2296, -0.6059, -0.9612, -0.3790,  1.0402,  0.0207,  0.2412,\n",
      "         -0.0493, -0.2957],\n",
      "        [-1.0602, -0.8063, -0.6567, -0.7645, -0.5367, -0.0387,  0.6275,  0.4452,\n",
      "         -0.2588, -0.1258],\n",
      "        [-0.0600, -0.2601, -0.5197, -0.6107, -0.4468, -0.5905,  0.8263,  0.8080,\n",
      "          0.6325,  0.1644],\n",
      "        [-0.5785, -0.7985, -0.2292, -0.4936, -0.5456,  0.1581,  0.3296,  0.7743,\n",
      "         -0.7408,  0.4100],\n",
      "        [-0.6140, -0.3987, -0.3719, -0.2202, -0.0667,  0.0707,  0.3396,  0.5382,\n",
      "          0.0061,  0.3166],\n",
      "        [-0.3849, -0.0831, -0.6228, -0.2236, -0.2476, -0.0279,  0.4019,  0.9415,\n",
      "          0.2267,  0.0811],\n",
      "        [-1.1149, -0.2818,  0.4875, -1.0463, -0.3840,  0.2421, -0.4282,  0.1173,\n",
      "          0.1929, -0.1161]], grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100,    2, -100, -100, -100, -100,    2, -100, -100,\n",
      "        -100,    2, -100,    2])\n",
      "field_name Amount\n",
      "nfeas 10\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[ 1.1174, -0.1594,  0.5260,  0.0320, -0.0921, -0.0314,  1.1299,  0.8288,\n",
      "          0.8077,  0.4252],\n",
      "        [ 1.0430,  0.0175,  0.6547, -0.7311,  0.2364,  0.0071,  0.4227,  0.2084,\n",
      "          0.4681,  0.4667],\n",
      "        [ 0.7454, -0.2902,  0.3047, -0.0565, -0.1082,  0.2071,  0.3705,  0.0520,\n",
      "          0.7401,  0.5641],\n",
      "        [ 0.5109, -0.2076,  0.4976, -0.0865,  0.1125,  0.0771,  0.6805,  0.5769,\n",
      "          0.4430,  0.3676],\n",
      "        [ 0.9251,  0.4731,  0.2438,  0.3999,  0.6376,  0.0755,  0.3000,  0.2208,\n",
      "          0.9525, -0.0647],\n",
      "        [ 0.7798,  0.0020,  0.9939,  0.3118, -0.0141, -0.2043,  1.5406,  0.5517,\n",
      "          0.2345, -0.1135],\n",
      "        [ 0.9524, -0.4238,  0.5232, -0.2333,  0.1976, -0.3418,  0.9913,  0.4429,\n",
      "          0.2622,  0.1908],\n",
      "        [ 0.8858, -0.0638,  0.2666,  0.0984,  0.1279,  0.1687,  0.7666,  0.6788,\n",
      "          0.2482, -0.1216],\n",
      "        [ 1.2088, -0.1086,  0.9363,  0.0376, -0.1607,  0.1830,  1.5447,  0.3920,\n",
      "         -0.5947,  0.1952],\n",
      "        [ 1.4001, -0.1904, -0.0752,  0.1810, -0.3162, -0.0125,  1.2240,  0.2118,\n",
      "         -0.0869, -0.1884],\n",
      "        [ 0.3843, -0.4138,  0.9463,  0.1805,  0.4126, -0.1162,  1.2372,  0.1980,\n",
      "          0.9954,  0.2969],\n",
      "        [ 0.8655,  0.1468,  0.0824,  0.8658, -0.1404,  0.1708,  1.1556,  1.0864,\n",
      "          0.5145,  0.2967],\n",
      "        [ 0.8127,  0.0049,  1.1666, -0.3290,  0.7433,  0.1233,  0.7061,  0.4408,\n",
      "          0.2227,  0.1908],\n",
      "        [ 0.4611, -0.7108,  0.5380, -0.1487,  0.4754, -0.0884,  0.5328,  0.2276,\n",
      "          0.5236, -0.2090],\n",
      "        [ 1.2864,  0.3032,  0.5467,  0.1283,  0.3805, -0.0337,  1.2112,  0.2711,\n",
      "          0.4866, -0.4080],\n",
      "        [ 1.5975,  0.2159,  0.7436, -0.0297, -0.0795,  0.3896,  1.3115,  0.3578,\n",
      "          0.9275,  0.2561],\n",
      "        [ 0.9240, -0.3905,  0.7123, -0.1699, -0.0456, -0.1711,  1.3212,  0.7499,\n",
      "          0.3138,  0.0425],\n",
      "        [ 1.2657, -0.1830,  0.5768,  0.2464,  0.0796,  0.0408,  0.9395,  0.0929,\n",
      "          0.4618,  0.2458],\n",
      "        [ 0.4588,  0.0439,  1.2619, -0.5018,  0.0514,  0.5106,  1.0022,  0.2255,\n",
      "          0.3185,  0.3555],\n",
      "        [ 0.1042, -0.3881,  0.4202,  0.0065,  0.1932,  0.2396,  0.7677,  0.9705,\n",
      "          0.4253,  0.4109],\n",
      "        [ 0.2654, -0.6332,  0.7620, -0.3702, -0.0878,  0.3027,  0.0900,  0.5653,\n",
      "          0.0992, -0.0421],\n",
      "        [ 0.5063, -0.1038,  0.3366, -0.2506,  0.4881,  0.3986,  0.1784,  0.5247,\n",
      "          0.6018, -0.1176],\n",
      "        [-0.7376, -0.1427,  0.1009,  0.6984,  0.1471,  0.8437,  0.0175, -0.1227,\n",
      "          0.3060,  0.6935],\n",
      "        [-0.1153, -0.5091,  0.5479,  0.4157,  0.4934,  0.4909,  0.2141,  0.4120,\n",
      "          0.5036, -0.1043],\n",
      "        [-0.5042, -0.0446,  0.3412, -0.4346,  0.5150,  0.4560, -0.2106,  0.2558,\n",
      "          0.0392,  0.1111],\n",
      "        [-0.2740,  0.0239,  1.0266,  0.2046,  0.3999,  0.3312,  0.3331, -0.2662,\n",
      "          0.6211, -0.3145],\n",
      "        [-0.0270, -0.5109,  0.2825,  0.4322, -0.3447, -0.1759,  0.3920,  0.4630,\n",
      "          0.0905, -0.2479],\n",
      "        [ 0.2328,  0.1963,  0.6313,  0.5724, -0.1429,  0.2558,  0.4308,  0.2794,\n",
      "          0.0601,  0.2421],\n",
      "        [-0.2212, -0.3418,  0.3427, -0.2212,  0.5221,  0.0343,  0.2192, -0.2839,\n",
      "         -0.1037, -0.2781],\n",
      "        [-0.0969, -0.3186,  0.5870,  0.2647,  0.4049,  0.2942, -0.0811,  0.0456,\n",
      "          0.5331,  0.0892],\n",
      "        [ 0.2249, -0.1310,  0.7231, -0.0423, -0.1251,  0.5973,  0.0639,  0.7297,\n",
      "         -0.5477,  0.2204],\n",
      "        [ 0.1297, -0.1935,  0.3600,  0.4738,  0.0402,  0.2250,  0.4908,  0.3404,\n",
      "          0.0387,  0.1865],\n",
      "        [ 0.0135, -0.1017,  0.3147, -0.0220, -0.0558,  0.6103,  0.3121,  0.2624,\n",
      "          0.2169, -0.4001],\n",
      "        [ 0.6089, -0.3096, -0.1344,  0.3812,  0.0334,  0.0994,  0.3083,  0.6860,\n",
      "          0.2139, -0.3786],\n",
      "        [ 0.0102, -0.0779,  0.5412, -0.6321,  0.3012,  0.4950,  0.1828,  0.3873,\n",
      "          0.4142,  0.1836],\n",
      "        [ 0.1294, -0.2849,  0.3900,  0.1021,  0.4469,  0.3007,  0.1544,  0.0976,\n",
      "          0.3112, -0.1852],\n",
      "        [-0.4341,  0.0488,  1.1926, -0.5751,  0.5052, -0.1981,  0.0321, -0.1251,\n",
      "         -0.0026,  0.1222],\n",
      "        [ 0.4583, -0.2470,  0.0202,  0.2783,  0.3180,  0.6927,  0.3428,  0.5756,\n",
      "          0.3588,  0.0762],\n",
      "        [ 0.2518, -0.0290,  0.9435, -0.4841, -0.3365,  0.6758, -0.2549,  0.3833,\n",
      "         -0.0934,  0.4503],\n",
      "        [-0.0283,  0.1025,  0.7098, -0.6506,  0.2982,  0.7686, -0.0053,  0.2612,\n",
      "          0.1732,  0.5893]], grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100,    6, -100, -100,    5, -100, -100, -100, -100,\n",
      "        -100,    3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100,    0, -100, -100,    1, -100, -100, -100,\n",
      "        -100,    4, -100, -100])\n",
      "field_name Use Chip\n",
      "nfeas 3\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[ 3.3770e-01,  3.1669e-01, -1.3096e-01],\n",
      "        [-4.6849e-03,  2.4890e-02,  5.8322e-02],\n",
      "        [ 2.8245e-01,  7.1291e-01,  3.0187e-01],\n",
      "        [-2.3042e-02,  4.4556e-01, -1.8477e-03],\n",
      "        [ 1.5896e-01,  4.7939e-01, -4.0589e-01],\n",
      "        [-4.6463e-01,  3.2766e-01, -6.2677e-01],\n",
      "        [-2.4630e-01, -7.5608e-01,  4.2485e-02],\n",
      "        [-2.1304e-01,  3.9426e-01, -4.4239e-01],\n",
      "        [ 4.8483e-01,  3.6063e-01, -5.5418e-01],\n",
      "        [ 1.0791e-01,  3.3363e-01,  1.1788e-01],\n",
      "        [-4.2793e-01,  3.5752e-01, -4.9179e-01],\n",
      "        [-4.1398e-01,  7.6895e-01, -1.1070e+00],\n",
      "        [-8.8845e-02,  3.2821e-01, -1.9564e-01],\n",
      "        [-1.3564e-01,  6.2797e-01, -1.8346e-01],\n",
      "        [-4.1635e-02,  1.6008e-01, -3.5174e-01],\n",
      "        [-5.7750e-01,  4.9141e-01,  1.5626e-01],\n",
      "        [ 7.3285e-02,  3.6655e-01,  2.4524e-01],\n",
      "        [-3.2594e-02,  5.7292e-01, -1.5731e-01],\n",
      "        [ 2.0327e-02,  5.1596e-01, -3.6116e-01],\n",
      "        [-4.6033e-01, -4.2814e-02,  1.6272e-02],\n",
      "        [ 6.9641e-01,  4.3961e-01,  2.3342e-01],\n",
      "        [ 4.5608e-01,  5.1636e-01, -1.9754e-02],\n",
      "        [ 3.2657e-01,  7.8874e-01, -6.9959e-01],\n",
      "        [ 3.4611e-01,  8.5286e-01,  2.9638e-02],\n",
      "        [-3.0006e-01,  1.3310e+00,  1.2541e-01],\n",
      "        [-2.5363e-02,  1.0506e+00, -1.1929e-01],\n",
      "        [ 3.0335e-01,  8.1533e-01,  1.2164e-01],\n",
      "        [ 1.0178e+00,  7.1181e-01, -3.8814e-01],\n",
      "        [ 4.3961e-01,  2.8220e-01,  4.5383e-01],\n",
      "        [ 4.5310e-01,  4.8667e-01,  2.4133e-02],\n",
      "        [-1.4431e-01,  1.9157e+00, -9.2845e-01],\n",
      "        [ 1.4223e-01,  1.3659e+00, -4.5557e-01],\n",
      "        [ 4.2207e-01,  6.6199e-01,  1.4851e-01],\n",
      "        [ 3.4970e-01,  5.1284e-02,  4.6795e-01],\n",
      "        [ 6.1735e-01,  4.3671e-01, -3.0004e-01],\n",
      "        [ 3.9652e-01,  9.1986e-01,  1.0345e-01],\n",
      "        [ 1.6732e-02,  1.5834e+00,  2.9676e-01],\n",
      "        [-3.1527e-01,  8.2568e-01, -4.7684e-02],\n",
      "        [ 1.8145e-01,  4.9841e-01,  1.4409e-01],\n",
      "        [ 7.1255e-01,  8.2938e-01,  3.2262e-01]], grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100,    0, -100, -100,    0, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100,    0,    0, -100, -100, -100, -100, -100, -100,\n",
      "           0, -100, -100, -100])\n",
      "field_name Merchant Name\n",
      "nfeas 5293\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[-0.8770,  0.2957,  0.2428,  ..., -0.0398,  0.1894,  0.5228],\n",
      "        [-1.0006,  0.3000,  0.1893,  ...,  0.0353, -0.0256,  0.4999],\n",
      "        [-0.8524,  0.4405,  0.3888,  ..., -0.2984,  0.4884,  0.3948],\n",
      "        ...,\n",
      "        [-0.8194,  0.1432,  0.6686,  ..., -0.5587, -0.0565,  0.6067],\n",
      "        [-0.0033, -0.3430,  0.6112,  ..., -0.8362,  0.3386,  0.2358],\n",
      "        [-0.4031, -0.2661,  0.7404,  ..., -0.8716, -0.1164,  0.0591]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([  17,   47, -100, -100, -100, -100, -100,  108, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100,    9,   20, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100,    4,  198, -100, -100,\n",
      "        -100, -100, -100, -100])\n",
      "field_name Merchant City\n",
      "nfeas 3151\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[ 0.7250,  0.5819, -0.7515,  ..., -0.6441, -0.6249,  0.3596],\n",
      "        [ 0.2374,  0.8117, -0.5436,  ..., -0.2174, -0.6658,  0.2449],\n",
      "        [ 0.5519,  0.5800,  0.5294,  ..., -0.2997,  0.0630,  0.1334],\n",
      "        ...,\n",
      "        [ 0.3858,  0.2362, -0.1461,  ..., -0.1712, -0.4692,  0.0632],\n",
      "        [ 0.3901,  0.6089,  0.2180,  ..., -0.0059, -0.0225,  0.2260],\n",
      "        [ 0.3319,  0.0627,  0.4019,  ...,  0.0771, -0.3403,  0.2003]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100,    1, -100, -100, -100, -100, -100,    1, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n",
      "field_name Merchant State\n",
      "nfeas 99\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[-0.4036, -0.1870, -0.5179,  ..., -0.5230, -0.1376, -0.2704],\n",
      "        [ 0.3911, -0.2898, -0.4080,  ..., -0.8329,  0.1605, -0.1832],\n",
      "        [ 0.1909,  0.2523, -0.3487,  ..., -0.3367, -0.0029,  0.4174],\n",
      "        ...,\n",
      "        [ 0.3613,  0.3653, -0.9220,  ..., -0.2724, -0.1930,  0.1956],\n",
      "        [ 0.4513,  1.0923, -0.6637,  ..., -1.0590, -0.0282,  0.1303],\n",
      "        [ 0.1520,  0.0273, -0.2986,  ..., -0.4784, -0.1102,  0.5856]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100,    2, -100, -100, -100, -100, -100, -100, -100, -100,    2, -100,\n",
      "        -100, -100, -100,    2, -100, -100,    2, -100, -100, -100, -100, -100,\n",
      "        -100,    3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n",
      "field_name Zip\n",
      "nfeas 5259\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[-0.4605, -0.1426, -0.0548,  ..., -0.1960,  0.3388,  0.6743],\n",
      "        [-0.7142, -0.6815, -0.1393,  ...,  0.1526,  0.5282,  0.2283],\n",
      "        [-0.8616,  0.2859, -0.0893,  ..., -0.2791,  0.2050,  0.6925],\n",
      "        ...,\n",
      "        [ 0.4413,  0.4887,  0.1420,  ..., -0.2763,  0.1115, -0.9219],\n",
      "        [ 0.4506,  0.1774,  0.4007,  ...,  0.0116,  0.2533, -0.3649],\n",
      "        [-0.2667,  0.2446, -0.4146,  ...,  0.0806, -0.3184, -0.7184]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100,   57,    0,    0, -100, -100,    0,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100,    2,    2,    2, -100, -100,    2, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n",
      "field_name MCC\n",
      "nfeas 109\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[-0.1240, -0.8830, -0.4285,  ...,  0.6805, -0.7570,  0.0500],\n",
      "        [-0.2841, -0.6486,  0.3897,  ...,  0.7913, -0.4998,  0.2777],\n",
      "        [ 0.5688, -0.5648, -0.0648,  ...,  0.2099, -0.6008,  0.1667],\n",
      "        ...,\n",
      "        [ 0.4090, -0.6682,  0.3189,  ...,  0.4262, -0.1205,  1.3753],\n",
      "        [-0.1122, -0.8694,  0.8017,  ...,  0.2432,  0.6861,  1.1396],\n",
      "        [ 0.3992, -0.6583,  0.4708,  ...,  0.4005,  0.0941,  1.4566]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100,    5, -100,    2,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,   15,\n",
      "        -100, -100,    0, -100, -100, -100, -100, -100, -100,   10, -100, -100,\n",
      "        -100, -100, -100, -100])\n",
      "field_name Errors?\n",
      "nfeas 16\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[ 5.6381e-01,  2.1908e-02,  2.9000e-01, -5.6401e-01,  1.6406e-01,\n",
      "         -1.3726e-01,  2.3083e-02, -1.1956e-01, -5.9174e-01, -1.1001e-01,\n",
      "         -2.7561e-01, -4.1011e-01,  9.2729e-01, -9.1935e-01, -2.2507e-01,\n",
      "         -2.2534e-02],\n",
      "        [ 4.6016e-02, -3.0940e-01,  2.7131e-01, -8.8010e-02, -1.1781e-01,\n",
      "          1.2646e-01,  1.3307e-01,  5.7231e-02, -7.3236e-01, -3.4552e-01,\n",
      "         -5.8635e-01, -5.1013e-01,  7.4768e-01, -3.1406e-01, -2.2781e-01,\n",
      "          2.8987e-01],\n",
      "        [ 7.4859e-01,  1.1970e-01,  7.8910e-01, -2.4278e-01,  9.9175e-02,\n",
      "         -1.5936e-01,  1.9447e-01,  5.0172e-01,  1.1641e-02, -2.9369e-01,\n",
      "         -3.5866e-02, -5.8592e-02,  9.7545e-01, -6.0656e-01,  1.5401e-01,\n",
      "         -3.9756e-01],\n",
      "        [ 4.6811e-01, -3.5588e-02,  4.2742e-01, -5.2690e-01,  3.0735e-01,\n",
      "          1.2652e-01, -2.4035e-02, -7.6258e-02, -1.0453e+00, -2.6586e-01,\n",
      "         -4.1418e-01, -5.2528e-01,  6.8702e-01, -4.9984e-01, -4.1499e-01,\n",
      "         -2.4537e-03],\n",
      "        [ 2.6953e-01, -2.5770e-01,  5.6700e-01, -6.0242e-01,  3.0327e-01,\n",
      "          2.2621e-01,  5.2270e-02,  1.6732e-01, -3.7781e-01, -3.6832e-01,\n",
      "         -3.0095e-01, -3.2443e-01,  1.1473e+00, -1.1061e+00, -6.7161e-01,\n",
      "          2.7284e-02],\n",
      "        [ 2.1325e-01, -1.7798e-01,  9.3281e-02, -6.3058e-01,  2.1253e-01,\n",
      "          2.3210e-01,  7.0527e-02,  1.2314e-01, -4.4602e-01, -1.5937e-01,\n",
      "         -1.0025e+00, -1.0103e-01,  5.6154e-01, -5.8627e-01, -4.9300e-01,\n",
      "          7.0487e-01],\n",
      "        [-4.1925e-02, -5.2672e-01,  8.9489e-02, -3.4015e-01,  2.5223e-01,\n",
      "          1.1553e-02,  1.1654e-02,  5.0800e-01, -7.6018e-01, -2.7688e-01,\n",
      "         -6.1259e-01, -6.5559e-02,  7.9388e-01, -4.1609e-01, -3.9444e-01,\n",
      "          4.0824e-01],\n",
      "        [-3.6986e-01, -4.1206e-01, -1.3616e-02, -3.8183e-01,  4.1431e-01,\n",
      "          1.5340e-01,  8.7316e-02,  4.9636e-01, -7.3890e-01, -6.5642e-01,\n",
      "         -4.8370e-01, -2.6138e-01,  7.6804e-01, -1.7205e-01, -8.1978e-01,\n",
      "          3.2265e-01],\n",
      "        [ 5.8252e-01,  2.1982e-02,  8.1458e-01, -5.9589e-01,  1.4645e-01,\n",
      "          3.2769e-01, -6.1298e-01,  5.9196e-02, -3.3169e-01, -8.7599e-01,\n",
      "         -6.9960e-01, -2.7701e-01,  5.4637e-01, -9.6977e-01, -4.1390e-01,\n",
      "         -1.8166e-03],\n",
      "        [ 4.4637e-01,  2.1199e-01,  6.4773e-01, -7.6159e-01,  6.7573e-01,\n",
      "         -1.1950e-01, -3.8344e-01, -2.1374e-01, -3.1933e-01, -2.7938e-02,\n",
      "         -1.5791e-01, -7.6841e-02,  3.5346e-01, -7.1494e-01, -3.3713e-01,\n",
      "         -1.9891e-02],\n",
      "        [ 4.5062e-02, -7.2254e-01, -2.8290e-03, -7.7547e-01, -1.7977e-01,\n",
      "         -2.7597e-01, -1.6523e-01, -8.6918e-02, -6.3358e-01, -7.5879e-01,\n",
      "         -3.1980e-01, -1.4989e-01,  8.5869e-01, -7.0479e-01, -9.3707e-01,\n",
      "          7.4436e-02],\n",
      "        [-1.5560e-01, -8.7867e-01,  4.7812e-01, -4.3828e-01,  3.4190e-01,\n",
      "          4.8381e-02,  2.2449e-01, -2.3536e-01, -4.5170e-01,  1.9899e-01,\n",
      "         -8.0736e-01,  1.1048e-01,  4.7069e-01, -3.6703e-01, -3.9084e-01,\n",
      "          3.5531e-01],\n",
      "        [ 6.3332e-01, -4.0467e-01, -9.6216e-03, -3.7997e-01,  4.6373e-01,\n",
      "         -2.2303e-01,  3.1340e-03,  2.6467e-01, -4.5051e-01, -4.9631e-01,\n",
      "         -5.8347e-01, -1.1240e-02,  6.2910e-01, -6.0810e-01, -3.8111e-01,\n",
      "         -3.7369e-02],\n",
      "        [ 5.5988e-01, -1.3522e-01,  2.8969e-01, -8.7248e-01,  2.0881e-01,\n",
      "          1.8409e-02,  7.0116e-02,  4.4672e-01, -5.5340e-01, -2.5774e-01,\n",
      "         -5.9245e-01,  2.5326e-01,  6.3505e-01, -8.3224e-01, -2.2624e-01,\n",
      "          3.4151e-01],\n",
      "        [-4.3607e-02, -2.5903e-01,  3.3852e-01, -6.8713e-01, -9.4080e-02,\n",
      "         -4.0648e-02,  4.4702e-01,  3.3493e-01, -4.7166e-01, -6.7955e-01,\n",
      "         -3.6794e-01, -2.1446e-01,  1.1255e+00, -1.0581e+00, -4.5384e-01,\n",
      "         -7.7452e-02],\n",
      "        [ 4.9883e-01, -1.4842e-02,  3.7719e-01, -4.3855e-01,  2.6134e-01,\n",
      "          4.7836e-01,  8.1197e-02,  2.4404e-01, -5.0860e-01, -4.6773e-01,\n",
      "          9.3659e-02, -7.9934e-01,  6.4625e-01, -5.7897e-01, -4.5533e-01,\n",
      "          3.4462e-01],\n",
      "        [ 9.4165e-01, -3.6465e-01,  3.8454e-01, -6.2171e-01, -3.6898e-01,\n",
      "         -8.9320e-02, -1.1238e-01,  1.0146e-01, -3.1392e-01, -1.6855e-01,\n",
      "         -3.5359e-01, -1.4467e-01,  8.2312e-01, -7.7630e-01, -2.7370e-01,\n",
      "          1.5116e-01],\n",
      "        [ 5.2360e-01, -1.9685e-01,  6.5048e-01, -6.4360e-01,  5.4321e-01,\n",
      "          3.9069e-01, -4.7902e-01,  3.6353e-01, -6.1611e-01, -1.6889e-02,\n",
      "         -6.3938e-02, -2.4469e-01,  2.8054e-01, -4.7657e-01, -4.9464e-02,\n",
      "         -4.0617e-01],\n",
      "        [ 2.0835e-01, -5.0014e-01,  5.9303e-02, -9.2387e-01,  8.5582e-02,\n",
      "         -7.7807e-03, -2.4710e-01,  1.8012e-02, -6.2614e-01, -1.3389e-01,\n",
      "         -4.0188e-01,  2.2681e-01,  8.4022e-01, -9.7123e-01, -8.1497e-01,\n",
      "          1.0438e-02],\n",
      "        [ 6.0257e-01, -4.1692e-01,  5.5485e-01, -5.7250e-01,  1.2759e-01,\n",
      "          5.4668e-02, -2.0735e-02,  1.9248e-01, -7.0427e-01, -1.0361e-01,\n",
      "         -2.0936e-01,  4.4458e-02,  1.0800e+00, -6.9821e-01, -6.8712e-01,\n",
      "         -4.9896e-01],\n",
      "        [ 8.2889e-02,  3.2572e-01,  2.4720e-01, -4.3392e-01,  8.1667e-01,\n",
      "         -1.2420e-01, -2.4618e-01,  4.3340e-01, -3.2753e-01, -4.4988e-02,\n",
      "         -2.7127e-01, -2.0769e-01,  1.2680e-01,  2.9671e-01,  2.9062e-01,\n",
      "          6.2528e-01],\n",
      "        [ 2.5236e-01, -8.4125e-02,  4.1940e-01, -5.8570e-01,  7.6524e-01,\n",
      "         -1.6791e-01, -3.1268e-01,  1.0218e-01,  6.0915e-02, -1.7763e-01,\n",
      "         -4.2756e-01, -4.1920e-01,  2.8567e-01, -5.3849e-01, -4.9037e-01,\n",
      "          1.9749e-01],\n",
      "        [ 3.3542e-01,  3.5626e-01,  1.5481e-01, -1.1901e+00,  1.0785e-01,\n",
      "          2.5591e-01,  3.0658e-01, -4.0590e-01, -1.0814e-01, -9.2093e-02,\n",
      "         -2.1651e-01, -5.6997e-01,  4.6781e-01, -6.1669e-01, -3.0953e-02,\n",
      "         -5.3787e-02],\n",
      "        [ 6.4219e-02, -2.4952e-01,  3.3652e-01,  4.6738e-02,  2.4668e-01,\n",
      "          2.2360e-02,  1.6791e-01,  5.3788e-01,  3.2282e-01,  3.2419e-01,\n",
      "         -6.4759e-01,  3.0396e-01,  4.3360e-01,  4.7649e-01,  1.2205e-01,\n",
      "          9.6029e-02],\n",
      "        [ 6.7059e-01, -1.0649e-01,  1.7873e-01, -2.6424e-01,  1.9828e-01,\n",
      "         -3.1954e-01, -1.1551e-01,  2.3978e-01, -5.4249e-01, -1.2268e-01,\n",
      "         -5.1013e-01, -1.1063e-01, -9.9608e-02,  4.0017e-01,  3.6193e-01,\n",
      "         -2.0192e-01],\n",
      "        [ 1.5084e-01,  2.3073e-01,  5.6551e-01, -1.7723e-01,  6.1189e-01,\n",
      "          3.6791e-01, -1.7279e-02, -3.4818e-01, -4.4664e-02, -7.2282e-02,\n",
      "         -9.0500e-01, -5.4666e-01,  5.6642e-01, -2.4429e-01, -6.0099e-01,\n",
      "          2.0838e-01],\n",
      "        [ 6.1668e-02, -1.6431e-01,  5.7256e-01,  4.5643e-01, -2.7208e-02,\n",
      "          2.2188e-01,  2.9472e-01,  5.3085e-01,  2.1405e-02,  4.4558e-01,\n",
      "         -3.5635e-01, -3.8220e-01,  5.1596e-01, -1.8497e-01, -5.2304e-01,\n",
      "         -5.1183e-01],\n",
      "        [ 5.3099e-01, -1.7602e-01,  1.3894e-01, -6.2367e-01,  6.2469e-01,\n",
      "          1.8662e-01,  2.1759e-01,  1.5272e-01, -1.3974e-01,  6.1878e-01,\n",
      "          2.9476e-02, -2.9720e-01,  3.8340e-01,  9.9633e-03, -4.4234e-01,\n",
      "          2.8312e-01],\n",
      "        [ 9.9460e-01, -1.7460e-01,  6.6225e-01, -4.5922e-01,  7.5386e-01,\n",
      "         -2.3642e-01, -5.5205e-02,  4.3144e-01, -1.7642e-01,  2.3433e-01,\n",
      "         -1.3750e-01, -5.4508e-02, -1.8862e-01, -1.3714e-01,  1.0786e-01,\n",
      "         -2.7780e-01],\n",
      "        [ 1.1136e+00, -1.1069e-01, -1.0138e-02, -1.0082e-01,  3.7878e-01,\n",
      "          3.6965e-01, -1.3128e-01,  8.8054e-01, -2.7188e-01,  5.7832e-01,\n",
      "          1.4707e-01, -4.3935e-01,  5.7468e-01,  6.2085e-01, -1.2161e-01,\n",
      "         -1.7912e-01],\n",
      "        [ 3.0603e-01,  3.4493e-01,  4.4424e-01, -5.2070e-01, -2.8127e-01,\n",
      "         -7.5208e-03,  2.1267e-01, -4.9917e-01, -4.5571e-01,  5.1020e-01,\n",
      "         -2.7686e-01, -5.0375e-01,  1.1182e+00, -2.6905e-01, -2.0048e-01,\n",
      "          6.8394e-01],\n",
      "        [ 2.9989e-03, -3.8047e-01,  1.3918e-01, -7.1530e-01,  4.5694e-01,\n",
      "         -4.0204e-01,  2.9134e-01,  2.7563e-01, -5.0730e-01,  1.2238e-01,\n",
      "         -1.6289e-01, -8.4267e-02,  5.3956e-01, -2.7254e-01,  2.5977e-02,\n",
      "          6.8203e-02],\n",
      "        [ 2.3336e-01,  4.8548e-01,  3.8842e-01,  1.2348e-01,  1.0646e-01,\n",
      "         -5.8875e-01, -4.2778e-01,  7.2166e-01, -3.3297e-01, -2.8540e-01,\n",
      "         -3.2214e-01, -5.3251e-02,  1.0038e+00,  1.4975e-01,  2.9609e-01,\n",
      "         -7.7136e-02],\n",
      "        [-1.8389e-02,  1.6763e-01, -9.7044e-02,  4.3078e-01, -1.2670e-03,\n",
      "          3.3795e-02, -3.2284e-01,  2.8812e-01, -5.3895e-01, -3.7806e-02,\n",
      "         -3.5499e-01, -4.7089e-01,  8.0179e-01, -1.5893e-02, -1.0100e-01,\n",
      "         -6.0444e-01],\n",
      "        [ 4.1609e-01, -3.2667e-01,  6.3785e-01, -3.5413e-01,  2.8202e-01,\n",
      "          3.0527e-01,  6.2433e-01,  6.4192e-01, -2.0586e-01,  5.0668e-02,\n",
      "         -3.8627e-01, -2.2559e-01,  5.1979e-01,  5.3903e-02,  4.0445e-01,\n",
      "          1.4104e-01],\n",
      "        [ 1.0693e+00,  7.8523e-01,  4.1773e-01, -3.2179e-02,  2.9040e-01,\n",
      "         -1.4268e-01, -1.9262e-01,  3.7542e-01, -5.4807e-01,  5.4346e-02,\n",
      "         -2.9660e-01, -3.3682e-01, -2.8255e-02, -1.7795e-01,  3.9925e-02,\n",
      "         -4.7945e-01],\n",
      "        [-4.1539e-02, -3.7689e-03,  4.4966e-01, -8.4090e-01,  2.3224e-01,\n",
      "          1.1916e-01,  3.2870e-01,  1.9348e-01,  4.5997e-02,  5.3527e-01,\n",
      "          1.9156e-01, -4.5582e-01,  4.6408e-01, -6.7705e-01, -5.4680e-03,\n",
      "          8.5919e-02],\n",
      "        [ 1.0731e+00,  4.5005e-01,  4.7247e-01,  1.7710e-01,  5.7920e-03,\n",
      "         -6.6505e-01, -1.5846e-01,  7.6318e-01, -4.5614e-01, -3.3689e-01,\n",
      "         -5.0109e-01, -1.9780e-01,  5.6084e-01,  1.2823e-01, -2.1348e-01,\n",
      "         -3.7415e-01],\n",
      "        [ 8.1331e-01, -2.0661e-01,  1.4991e-01, -8.0438e-01,  7.5240e-01,\n",
      "         -3.8501e-01, -2.1590e-04,  3.6537e-01, -7.9646e-01, -2.9914e-02,\n",
      "         -2.5741e-03,  2.6239e-02,  1.9054e-01, -1.7980e-01,  9.2348e-02,\n",
      "         -2.1319e-01],\n",
      "        [ 4.2048e-01,  1.1563e-01,  3.0142e-01, -3.0124e-01,  9.3753e-02,\n",
      "          2.5055e-01, -5.4076e-02,  1.7042e-01, -5.7373e-01,  1.3724e-01,\n",
      "         -6.8993e-01, -6.5301e-01,  7.8083e-01, -2.5033e-01, -3.1277e-01,\n",
      "         -3.3914e-02]], grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "           0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n",
      "field_name SPECIAL\n",
      "nfeas 7\n",
      "loss_fct CrossEntropyLoss()\n",
      "prediction_scores.device cpu\n",
      "Prediction score for loss - tensor([[ 0.0000e+00,  1.8429e-01, -4.5017e-01,  2.2805e-01,  4.7725e-01,\n",
      "          2.0561e-01,  6.6261e-02],\n",
      "        [ 0.0000e+00,  2.8377e-01,  6.1717e-03, -6.9672e-03,  1.8648e-01,\n",
      "          4.7812e-02,  3.7022e-01],\n",
      "        [ 0.0000e+00, -3.1622e-01, -5.0697e-01,  5.5955e-01,  1.9344e-01,\n",
      "         -4.8636e-01,  2.4999e-01],\n",
      "        [ 0.0000e+00, -1.5827e-01,  1.2186e-01,  1.6725e-01,  3.0235e-01,\n",
      "         -1.2398e-01, -3.1364e-01],\n",
      "        [ 0.0000e+00, -1.8436e-01, -2.2015e-01,  1.8582e-01,  5.6368e-01,\n",
      "          4.3561e-01,  3.8033e-01],\n",
      "        [ 0.0000e+00, -2.9921e-02, -4.2864e-01, -1.2785e-02,  8.0653e-02,\n",
      "          1.3451e-01, -5.9624e-03],\n",
      "        [ 0.0000e+00, -2.6402e-01, -5.6365e-02, -4.5458e-01, -5.9248e-02,\n",
      "          2.2167e-01, -1.4177e-01],\n",
      "        [ 0.0000e+00, -1.0945e-01,  2.6970e-01,  3.0960e-01,  2.9864e-01,\n",
      "          5.2821e-02,  3.2674e-01],\n",
      "        [ 0.0000e+00, -2.5776e-01, -1.8925e-01, -3.5968e-01,  1.5093e-01,\n",
      "         -8.1640e-02,  2.3440e-01],\n",
      "        [ 0.0000e+00,  3.0465e-01, -3.5058e-01,  1.7608e-01,  3.1753e-01,\n",
      "          3.2449e-01,  5.8420e-01],\n",
      "        [ 0.0000e+00,  2.1286e-01,  7.0074e-01,  3.2355e-01,  3.3946e-01,\n",
      "          2.7190e-01,  1.2824e-01],\n",
      "        [ 0.0000e+00, -1.0995e-01,  1.4264e-01, -5.5022e-01,  3.2042e-01,\n",
      "         -1.1476e-01,  4.0041e-01],\n",
      "        [ 0.0000e+00, -4.4446e-01,  4.5697e-01, -1.7364e-01,  2.0789e-01,\n",
      "          5.6716e-02,  1.5512e-01],\n",
      "        [ 0.0000e+00, -2.5332e-01,  5.7846e-03,  4.1432e-01,  2.6919e-01,\n",
      "          1.1539e-01, -8.2224e-02],\n",
      "        [ 0.0000e+00, -2.2619e-01, -3.7304e-01, -3.1343e-01,  4.4744e-01,\n",
      "          3.0037e-01,  7.9960e-01],\n",
      "        [ 0.0000e+00,  7.8051e-01, -3.5990e-01, -1.7315e-01,  1.8515e-01,\n",
      "          1.9005e-01,  3.6438e-01],\n",
      "        [ 0.0000e+00, -7.6923e-01, -5.5413e-01,  1.1944e-02,  2.4590e-01,\n",
      "          1.8251e-01,  7.6620e-02],\n",
      "        [ 0.0000e+00, -1.0952e-03,  2.3233e-01,  2.1508e-01,  1.3560e-01,\n",
      "         -7.0969e-02, -3.5873e-02],\n",
      "        [ 0.0000e+00,  8.6525e-02, -1.0545e-01,  7.5212e-01,  3.2275e-01,\n",
      "         -2.1648e-01,  4.3695e-01],\n",
      "        [ 0.0000e+00,  2.8070e-01, -9.5698e-02,  1.8004e-01,  1.0328e-01,\n",
      "          1.2838e-01,  6.8028e-01],\n",
      "        [ 0.0000e+00,  5.8305e-01,  6.1822e-01, -6.1137e-01, -5.3894e-02,\n",
      "         -1.4124e-01,  6.8849e-01],\n",
      "        [ 0.0000e+00,  5.5096e-01,  4.0322e-01,  9.9308e-02,  2.8083e-01,\n",
      "         -2.7457e-01,  1.1436e+00],\n",
      "        [ 0.0000e+00, -1.8324e-01,  1.3427e+00, -3.0473e-01,  2.5753e-01,\n",
      "         -3.0721e-01,  4.9697e-01],\n",
      "        [ 0.0000e+00, -1.1713e-01,  7.0976e-01, -1.8202e-02,  2.8714e-01,\n",
      "          1.0724e-01,  4.9539e-01],\n",
      "        [ 0.0000e+00,  2.9969e-01,  3.4744e-01, -1.5000e-01, -1.7547e-01,\n",
      "         -6.2573e-01,  6.7513e-01],\n",
      "        [ 0.0000e+00,  1.5882e-01, -1.2105e-01,  2.1599e-01,  2.9827e-01,\n",
      "          1.3170e-01,  7.9261e-01],\n",
      "        [ 0.0000e+00, -1.8689e-01,  1.0928e+00,  4.8833e-01,  9.7562e-03,\n",
      "          1.1211e-01,  5.0217e-01],\n",
      "        [ 0.0000e+00, -4.3052e-01,  3.7444e-01, -1.8911e-01,  4.7885e-02,\n",
      "         -3.5397e-01,  5.3020e-01],\n",
      "        [ 0.0000e+00,  4.0330e-01,  7.2711e-01, -1.0911e-01, -3.8452e-02,\n",
      "         -2.7334e-01,  5.0475e-01],\n",
      "        [ 0.0000e+00,  3.6603e-01,  4.7145e-01, -2.2345e-02, -2.0737e-02,\n",
      "          5.4871e-02,  8.2010e-01],\n",
      "        [ 0.0000e+00,  8.8272e-02,  9.7535e-01, -1.9421e-02, -3.1828e-01,\n",
      "         -4.4969e-01,  8.5094e-03],\n",
      "        [ 0.0000e+00,  3.5751e-01,  7.0251e-01,  9.4309e-02,  1.1315e-01,\n",
      "          9.9226e-03,  4.4745e-01],\n",
      "        [ 0.0000e+00, -3.2549e-02,  8.1880e-01,  4.2361e-02,  1.5863e-02,\n",
      "         -1.3542e-02,  2.1682e-01],\n",
      "        [ 0.0000e+00,  6.4770e-01, -6.3708e-02, -7.3991e-02,  4.2902e-01,\n",
      "         -4.2526e-02,  9.7913e-01],\n",
      "        [ 0.0000e+00,  9.0615e-02,  1.0152e+00, -2.7475e-01, -1.9759e-01,\n",
      "         -9.1232e-02,  5.0051e-01],\n",
      "        [ 0.0000e+00,  4.9732e-01,  6.1832e-01,  3.5434e-01,  1.7289e-01,\n",
      "         -2.0514e-01,  5.7951e-01],\n",
      "        [ 0.0000e+00,  2.5480e-01,  9.1367e-02, -2.0633e-02,  3.4574e-02,\n",
      "         -3.4400e-01,  6.0793e-01],\n",
      "        [ 0.0000e+00,  2.1153e-01,  6.2111e-01,  7.0981e-02,  6.4256e-02,\n",
      "         -3.4739e-01,  7.6735e-01],\n",
      "        [ 0.0000e+00,  2.7512e-01,  5.7829e-02,  3.1748e-01,  3.5905e-01,\n",
      "          1.2200e-01,  8.2417e-01],\n",
      "        [ 0.0000e+00,  3.3021e-01,  8.2955e-01,  8.2055e-02,  3.2674e-01,\n",
      "         -4.2332e-01,  1.2908e-01]], grad_fn=<ViewBackward0>)\n",
      "Masked score for loss - tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n",
      "out (tensor(nan, grad_fn=<AddBackward0>), tensor([[[ 0.0000e+00, -1.3204e+00,  3.3056e-01,  ...,  2.6401e-01,\n",
      "           5.1555e-01, -2.0907e-01],\n",
      "         [ 0.0000e+00, -2.7074e-01,  4.2247e-02,  ...,  2.3336e-01,\n",
      "           4.6827e-01, -1.6261e-01],\n",
      "         [ 0.0000e+00,  5.9677e-01,  1.0306e+00,  ..., -2.4378e-01,\n",
      "          -8.6925e-03,  1.3450e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -3.0687e-01,  4.4990e-01,  ...,  7.4861e-01,\n",
      "           9.3779e-01, -5.1870e-01],\n",
      "         [ 0.0000e+00, -2.5150e-01, -3.2721e-01,  ..., -4.9896e-01,\n",
      "          -1.1244e+00, -2.8718e-01],\n",
      "         [ 0.0000e+00,  2.8070e-01, -9.5698e-02,  ..., -1.4137e-01,\n",
      "           4.2785e-01,  2.9240e-01]],\n",
      "\n",
      "        [[ 0.0000e+00, -6.5011e-01, -7.6206e-04,  ..., -4.3185e-01,\n",
      "          -9.0254e-02,  8.1540e-02],\n",
      "         [ 0.0000e+00,  2.9216e-01, -2.1558e-02,  ...,  6.0106e-01,\n",
      "          -3.2392e-01,  4.1684e-01],\n",
      "         [ 0.0000e+00,  5.7798e-01,  1.1031e+00,  ..., -1.2289e-01,\n",
      "          -5.6002e-01,  6.1073e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -4.9975e-01,  2.0938e-01,  ..., -6.1324e-03,\n",
      "          -1.1608e+00, -6.0014e-01],\n",
      "         [ 0.0000e+00,  3.3019e-01,  6.0132e-01,  ..., -3.3914e-02,\n",
      "          -1.1176e+00, -1.0745e-01],\n",
      "         [ 0.0000e+00,  3.3021e-01,  8.2955e-01,  ...,  6.1130e-01,\n",
      "          -6.7942e-01, -4.7070e-01]]], grad_fn=<ViewBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "for inps in tqdm(train_dataloader):\n",
    "    #print(inps.keys())\n",
    "    #print(inps['input_ids'].shape)\n",
    "    #print(inps['masked_lm_labels'].shape)\n",
    "    #print(inps['masked_lm_labels'], )\n",
    "    optim.zero_grad()\n",
    "    #print(inps['input_ids'].shape)\n",
    "    labels = inps.pop(\"Ouput\")\n",
    "    model.train()\n",
    "    inps['input_ids'] = inps['input_ids']\n",
    "    inps['masked_lm_labels'] = inps['masked_lm_labels']\n",
    "    outputs =model(**inps)\n",
    "    print('out',outputs)\n",
    "    break\n",
    "    loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    #print(loss)\n",
    "    # print(len(aa))\n",
    "    # print(\"Length of out - \", len(out))\n",
    "    # print('Ouput -', out[0].shape)\n",
    "    # #print('Ouput -', out[1].shape)\n",
    "    # print(aa[0])\n",
    "    # print(aa[1].shape)\n",
    "    # #aa.last_hidden_state\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "sam1 = torch.rand((40, 1))\n",
    "sam2 = torch.rand((40, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43msam1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msam2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:1159\u001b[0m, in \u001b[0;36mCrossEntropyLoss.__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m   1158\u001b[0m              reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index \u001b[38;5;241m=\u001b[39m ignore_index\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m=\u001b[39m label_smoothing\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:25\u001b[0m, in \u001b[0;36m_WeightedLoss.__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_WeightedLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m, weight)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight: Optional[Tensor]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:18\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28msuper\u001b[39m(_Loss, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction \u001b[38;5;241m=\u001b[39m reduction\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/_reduction.py:35\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mand\u001b[39;00m reduce:\n\u001b[1;32m     36\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m reduce:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "CrossEntropyLoss(sam1, sam2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(total_loss/len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('new_mode1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "#                                   vocab=vocab,\n",
    "#                                   field_ce=config['field_ce'],\n",
    "#                                   flatten=config['flatten'],\n",
    "#                                   ncols=dataset.ncols,\n",
    "#                                   field_hidden_size=config['field_hs']\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model.save_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_val = torch.load('new_mode1/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(loaded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model = tab_net.model.tb_model.from_pretrained('new_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(tab_net.model.tb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_net.model.tb_model.bert.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-23c5aa56e56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_classifier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlstm_classfr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_classfr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import models.lstm_classifier as lstm_classfr\n",
    "reload(lstm_classfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_fe_model = tab_net.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = lstm_classfr.LSTM(emb_inp_size=1062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                  vocab=vocab,\n",
    "                                  field_ce=config['field_ce'],\n",
    "                                  flatten=config['flatten'],\n",
    "                                  ncols=dataset.ncols,\n",
    "                                  field_hidden_size=config['field_hs']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_cls = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, custom_special_tokens,\n",
    "                 vocab,\n",
    "                 field_ce,\n",
    "                 flatten,\n",
    "                 ncols,\n",
    "                 field_hidden_size,\n",
    "                 bert_feature_size,\n",
    "                 base_model\n",
    "                 ):\n",
    "        super(Classifier, self).__init__()\n",
    "        '''\n",
    "        self.tab_net = TabFormerBertLM(custom_special_tokens,\n",
    "                                        vocab=vocab,\n",
    "                                        field_ce=field_ce,\n",
    "                                        flatten=flatten,\n",
    "                                        ncols=ncols,\n",
    "                                        field_hidden_size=field_hidden_size)\n",
    "        '''\n",
    "        loaded_val = torch.load('new_mode1/pytorch_model.bin')\n",
    "        base_model.load_state_dict(loaded_val)\n",
    "        #print(base_model)\n",
    "        for p in base_model.parameters():\n",
    "            p.requires_grad = True\n",
    "        self.field_transformer = base_model.tab_embeddings\n",
    "        self.bert = base_model.tb_model\n",
    "        \n",
    "\n",
    "\n",
    "        self.classifier = lstm_classfr.LSTM(emb_inp_size=bert_feature_size)\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids ,input_args):\n",
    "        field_embeddings = self.field_transformer(input_ids)\n",
    "        #input_args['input_ids'] = input_ids\n",
    "        bert_features = self.bert(inputs_embeds=field_embeddings, **input_args)\n",
    "        \n",
    "        bert_features = bert_features[1]\n",
    "        print(bert_features.shape)\n",
    "        bert_features = bert_features.reshape((50, 20, 11, 8721))\n",
    "        bert_features = bert_features.reshape((50, 220, 8721))\n",
    "        cls_out = self.classifier(bert_features, T.as_tensor(([11])))\n",
    "        \n",
    "        return cls_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = Classifier(custom_special_tokens,\n",
    "                 vocab=vocab,\n",
    "                    field_ce=config['field_ce'],\n",
    "                    flatten=config['flatten'],\n",
    "                    ncols=dataset.ncols,\n",
    "                    field_hidden_size=config['field_hs'],\n",
    "                 bert_feature_size=8721, base_model=model)\n",
    "classif = classif.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.tb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([232])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as T\n",
    "T.as_tensor(([232]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_fn = torch.optim.Adadelta(params=classif.parameters(), lr=0.1, rho=0.95, eps=1e-08)\n",
    "loss_fn = T.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'masked_lm_labels', 'Ouput'])\n",
      "torch.Size([50, 220, 8721])\n",
      "inp_shaep torch.Size([50, 220, 8721])\n",
      "Before fc torch.Size([1, 256])\n",
      "After fc torch.Size([1, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-92acd7c26510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked_lm_labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked_lm_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclassif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-b9c2b773b164>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_args)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mbert_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8721\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mbert_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8721\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcls_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/murugesh/Clinical-Transformer/models/lstm_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp_emb, inp_len)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#text_fea = torch.squeeze(text_fea, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After fc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_fea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtext_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_fea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "for inps in train_dataloader:\n",
    "    print(inps.keys())\n",
    "    input_ids = inps.pop('input_ids')\n",
    "    out = inps.pop('Ouput')\n",
    "    classif.train()\n",
    "    \n",
    "    #print(out)\n",
    "    #print(input_ids.shape)\n",
    "    #print(inps['masked_lm_labels'].shape)\n",
    "    #print(inps['masked_lm_labels'], )\n",
    "    #print(inps[0].shape)\n",
    "    #print(inps[1].shape)\n",
    "    input_ids = input_ids.to('cuda:3')\n",
    "    inps['masked_lm_labels'] = inps['masked_lm_labels'].to('cuda:3')\n",
    "    preds =classif(input_ids, inps)\n",
    "    print(preds)\n",
    "    preds = preds.view(preds.size(0))\n",
    "    loss = loss_fn(preds.float(), out.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Class out - {class_out.shape}\")\n",
    "    print(class_out)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. append classifier with bert\n",
    "2. Freeze bert model after first train\n",
    "3. Use bert model and train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = T.nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(hn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(hn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
